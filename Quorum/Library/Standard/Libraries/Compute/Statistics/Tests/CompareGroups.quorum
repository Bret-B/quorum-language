package Libraries.Compute.Statistics.Tests

use Libraries.Compute.Statistics.DataFrameCalculation
use Libraries.Compute.Statistics.DataFrame
use Libraries.Compute.Statistics.DataFrameColumn
use Libraries.Compute.Statistics.Calculations.Mean
use Libraries.Compute.Statistics.Calculations.Variance
use Libraries.Compute.Math
use Libraries.Containers.Array
use Libraries.Compute.Statistics.Inputs.ColumnInput
use Libraries.Compute.Vector
use Libraries.Compute.Statistics.Calculations.Summarize
use Libraries.Compute.Statistics.Distributions.VarianceRatioDistribution
use Libraries.Compute.Statistics.Distributions.HeavyTailNormalDistribution
use Libraries.Compute.Statistics.Inputs.FactorInput
use Libraries.Containers.HashTable
use Libraries.Containers.Iterator
use Libraries.Compute.Statistics.Reporting.CompareGroupsResult
use Libraries.Compute.Statistics.Reporting.Compare1GroupResult
use Libraries.Compute.Statistics.Reporting.Compare2GroupsResult
use Libraries.Compute.Statistics.Reporting.CompareNGroupsResult
use Libraries.Compute.Statistics.Columns.NumberColumn
use Libraries.Compute.Statistics.Reporting.CompareVariancesResult
use Libraries.Compute.Statistics.Distributions.StudentizedRangeDistribution

/*
    This class implements several parametric tests:
        CompareGroupToMean is a One-Sample T-Test. 
        Difference between one group and a given mean
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test

        Compare2DependentGroups is a Paired T-Test
        Difference between two paired groups and a given mean
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test 

        Compare2IndependentGroups is a Two-Sample T-Test
        Difference between two groups when groups have equal variances
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test

        Compare2IndependentGroups is a Welch's Two-Sample T-Test. 
        Difference between two groups when groups have unequal variances
        For more information: https://en.wikipedia.org/wiki/Welch%27s_t-test       

        CompareNIndependentGroups is a One-Way Analysis Of Variance (ANOVA)
        Difference between several groups when groups have equal variances
        For more information: https://en.wikipedia.org/wiki/One-way_analysis_of_variance

        CompareNIndependentGroups is a Welch's One-Way Analysis Of Variance (ANOVA) 
        Difference between several groups when groups have unequal variances
        For more information: https://en.wikipedia.org/wiki/One-way_analysis_of_variance

        CompareNDependentGroups is a Repeated Measures One-Way Analysis Of Variance (ANOVA)
        Difference between several groups when there are repeated measures
        For more information: https://en.wikipedia.org/wiki/Repeated_measures_design

        _____________ is a One-Way Analysis Of Covariance (ANCOVA)
        Difference between several groups while controlling for nuisance variables
        For more information: https://en.wikipedia.org/wiki/Analysis_of_covariance

        _____________ is a One-Way Multivariate Analysis Of Variance (MANOVA). 
        Difference between several groups on more than one dependent variable
        For more information: https://en.wikipedia.org/wiki/Multivariate_analysis_of_variance

    It was partially adapted from the same model in Apache Commons, but was expanded 
    upon to simplify the library and add a variety of helper actions that were missing.
    More information about this class can be found on its documentation page OneWayAnova and TTest:
    https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html

    Attribute: Author Andreas Stefik, Hannah Williams
    Attribute: Example

    use Libraries.Compute.Statistics.DataFrame
    use Libraries.Compute.Statistics.Tests.CompareGroups

    DataFrame frame
    frame:Load("Data/Data.csv")

    CompareGroups compare
    compare:AddColumn(0)
    compare:AddColumn(1)
    frame:Calculate(compare)

    output compare:GetFormalSummary()
*/
class CompareGroups is StatisticalTest
    /* The distribution used to calculate the p-value in N-sample tests.*/
    VarianceRatioDistribution fDistribution

    /* The distribution used to calculate the p-value in 2-sample tests.*/
    HeavyTailNormalDistribution tDistribution

    /* The distribution used to calculate the p-value in N-sample tukey correction tests.*/
    StudentizedRangeDistribution qDistribution

    /* This stores a hash of all of the results. */
    HashTable<text, CompareGroupsResult> results            

    /* Flag if the samples are paired in a two-sample test */
    boolean paired = false

    /* Flag if repeated measures are used in one-way within-subjects anova */
    boolean repeatedMeasures = false

    /* Flag if calculations are to assume variances are equal or not */
    boolean assumeEqualVariances = true

    /* Flag if variances are found to be equal or not */
    boolean equalVariances = false

    /* Flag if requested to test variance assumptions */
    boolean testVarianceAssumption = false

    /* Flag if calculations are to assume normal distribution or not */
    boolean assumeNormalDistribution = true

    /* Flag if distribution is found to be normal or not */
    boolean normalDistribution = false

    /* Flag if requested to test distribution assumptions */
    boolean testDistributionAssumption = false

    /* Flag to determine if family-wise correction is applied or not in N-sample tests */
    boolean correctFamilyWiseError = true

    /* Flag to determine if bonferroni correction is applied or not in N-sample tests */
    boolean useBonferroniCorrection = true

    /* Flag to determine if tukey HSD correction is applied or not in N-sample tests */
    /* This is only applicable in an independent N-sample test */
    boolean useTukeyCorrection = false

    /* Flag for user to force the pairwise computations to take place when applicable */
    boolean mustCalculatePairwise = false

    /* Flag to ensure requested N-sample test is run even if there are only 2 samples */
    private boolean userRequestedNSampleTest = false

    /* User determined mean to be used in one-sample or paired two-sample tests */
    number userMean = 0

    Math math

    action Calculate(DataFrame frame) 
        if paired or repeatedMeasures
            parent:StatisticalTest:RemoveUndefined(true)
        end
        if GetFactorSize() = 0
            parent:StatisticalTest:Calculate(frame)
        else
            parent:StatisticalTest:CalculateWithFactor(frame)
        end
    end

    private action RunTest(DataFrame frame)
        if GetColumnSize() < 1
            alert("Must include at least one column.")
        end

        if GetColumnSize() = 1
            CompareGroupToMean(frame)
        elseif GetColumnSize() = 2 and not userRequestedNSampleTest     
            if paired or repeatedMeasures
                Compare2DependentGroups(frame)
            else             
                Compare2IndependentGroups(frame)
            end
        else 
            if paired or repeatedMeasures
                CompareNDependentGroups(frame)
            else
                CompareNIndependentGroups(frame)
            end
        end
    end

    /* 
        One-way analysis of variance (ANOVA) for 3 or more independent groups.

        Assumptions:
            1. Two or more samples:
                If two samples: Best to use a Two-Sample T-Test     > CompareGroups:Compare2IndependentGroups
              
            2. Samples are independent:
                If not independent: Use a Repeated Measures Anova   > CompareGroups:CompareNDependentGroups

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Kruskal-Wallis Test            > CompareRanks:CompareNIndependentRanks

            4. Samples have equal variances:
                To test this: Use a Levene's Test                   > CompareVariances:CompareIndependentVariances
                If not equal: Use Welch's Anova                     > CompareGroups:AssumeEqualVariances(false)

        Null hypothesis: The means are equal across all samples.
        Alternative hypothesis: At least one mean is not equal to the others.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumns(0)
        frame:AddSelectedColumns(1)
        frame:AddSelectedColumns(2)
    
        CompareGroups compare = frame:CompareSelectedColumns()
        output compare:GetSummary()
    */
    action CompareNIndependentGroups(DataFrame frame)
        if GetFactorSize() > 0
            userRequestedNSampleTest = true
            me:Calculate(frame) // The factor needs to be processed
        else
            if GetColumnSize() < 2
                alert("CompareNIndependentGroups must have at least 2 groups.")
            end

            CompareNGroupsResult result
            // Assumption Testing
            if testVarianceAssumption
                // Run a Levene's CompareVariances test 
                CompareVariances compare
                i = 0
                repeat while i < GetColumnSize()
                    compare:AddColumn(GetColumn(i))
                    i = i + 1
                end
                compare:CompareIndependentVariances(frame)
                if compare:GetProbabilityValue() < GetSignificanceLevel()
                    equalVariances = false  // Significantly different
                else
                    equalVariances = true   // Approximately equal
                end
                result:SetCompareVariancesResult(compare:GetResult())
            end

            // Used in equal variances anova
            integer totalSize = 0
            number degreesFreedomWithinGroup = 0
            number degreesFreedomBetweenGroup = GetColumnSize() - 1
            number sumOfSquaresWithinGroup = 0
            number sumOfSquaresBetweenGroup = 0
            number totalSum = 0
            number totalSumOfSquares = 0
             
            // Used in welch's unequal variances anova
            // For more information: https://www.discoveringstatistics.com/docs/welchf.pdf
            number totalSumOfWeights = 0
            number totalWeightedMean = 0            
            Array<number> weights
            Array<number> sizes

            Array<DataFrameColumn> groups
            Array<Summarize> summaries
            i = 0
            repeat while i < GetColumnSize()
                DataFrameColumn column = frame:GetColumn(GetColumn(i))
                if column:IsUndefined()
                    alert("Column is undefined.")
                end
    
                if not column:IsNumberColumn() and not column:IsIntegerColumn()
                    alert("Columns must be numerical. " + column:GetHeader() + " is not a numerical column.")
                end
                groups:Add(column)
    
                // Assumption Testing
                if testDistributionAssumption
                    // Run a Shapiro-Wilk's CompareDistributions Test
                    CompareDistributions compare
                    compare:AddColumn(GetColumn(i))
                    compare:CompareDistributionToNormal(frame)
                    if compare:GetProbabilityValue() < GetSignificanceLevel()
                        normalDistribution = false  // Not normal
                    else
                        normalDistribution = true   // Maybe normal
                    end
                end

                Summarize summarize
                column:Calculate(summarize)
                summaries:Add(summarize)
                totalSize = totalSize + column:GetSize()
                if equalVariances or assumeEqualVariances
                    totalSum = totalSum + summarize:GetSum()
                    totalSumOfSquares = totalSumOfSquares + summarize:GetSumOfSquares()
                    degreesFreedomWithinGroup = degreesFreedomWithinGroup + column:GetSize() - 1
        
                    number ss = summarize:GetSumOfSquares() - (summarize:GetSum() * summarize:GetSum() / column:GetSize())
                    sumOfSquaresWithinGroup = sumOfSquaresWithinGroup + ss
                else
                    number weight = column:GetSize() / summarize:GetVariance()
                    totalSumOfWeights = totalSumOfWeights + weight
                    totalWeightedMean = totalWeightedMean + weight * summarize:GetMean()
                    weights:Add(weight)
                    sizes:Add(column:GetSize())
                end
                i = i + 1
            end
    
            if equalVariances or assumeEqualVariances
                totalSumOfSquares = totalSumOfSquares - (totalSum * totalSum / totalSize)
                sumOfSquaresBetweenGroup = totalSumOfSquares - sumOfSquaresWithinGroup
                number eta = sumOfSquaresBetweenGroup / totalSumOfSquares
                number meanSumOfSquaresBetweenGroup = sumOfSquaresBetweenGroup / degreesFreedomBetweenGroup
                number meanSumOfSquaresWithinGroup = sumOfSquaresWithinGroup / degreesFreedomWithinGroup

                number f = meanSumOfSquaresBetweenGroup / meanSumOfSquaresWithinGroup        
                fDistribution:Setup(degreesFreedomBetweenGroup, degreesFreedomWithinGroup)
                number p = 1.0 - fDistribution:CumulativeDistribution(f)
                number criticalFValue = f //fDistribution:InverseCumulativeDistribution(GetSignificanceLevel())
                number pooledSD = math:SquareRoot(meanSumOfSquaresWithinGroup)
        
                // Only necessary to calculate pairwise if the anova null hypothesis has failed or if requested
                Array<CompareGroupsResult> pairwise 
                if p <= GetSignificanceLevel() or mustCalculatePairwise
                    pairwise = ComputePairwiseTests(frame, summaries, pooledSD, degreesFreedomWithinGroup)
                end

                result:SetSumOfSquaresBetweenGroups(sumOfSquaresBetweenGroup)
                result:SetSumOfSquaresWithinGroups(sumOfSquaresWithinGroup)
                result:SetDegreesOfFreedomBetweenGroups(degreesFreedomBetweenGroup)
                result:SetDegreesOfFreedomWithinGroups(degreesFreedomWithinGroup)
                result:SetMeanSumOfSquaresBetweenGroups(meanSumOfSquaresBetweenGroup)
                result:SetMeanSumOfSquaresWithinGroups(meanSumOfSquaresWithinGroup)
                result:SetCriticalValue(criticalFValue)
                result:SetTestStatistic(f)
                result:SetProbabilityValue(p)
                result:SetEffectSize(eta)
                result:SetEffectSizeName("Eta-Squared")
                result:SetPairwiseResults(pairwise)
                result:SetFormalTestName("One-Way Analysis of Variance")
            else
                // Assumption of equal variances has been violated
                // For more information: https://www.rips-irsp.com/articles/10.5334/irsp.198/

                // Calculate welch's F
                // For more information: https://www.discoveringstatistics.com/docs/welchf.pdf
                totalWeightedMean = totalWeightedMean / totalSumOfWeights

                number sumOfWeightedSquares = 0
                number sumForLambda = 0
                i = 0
                repeat while i < weights:GetSize()
                    number value1 = (1 - (weights:Get(i) / totalSumOfWeights))
                    sumForLambda = sumForLambda + (value1 * value1 / (sizes:Get(i) - 1))

                    number value2 = summaries:Get(i):GetMean() - totalWeightedMean
                    sumOfWeightedSquares = sumOfWeightedSquares + weights:Get(i) * (value2 * value2)
                    i = i + 1
                end
                number lambda = (3 * sumForLambda) / (GetColumnSize() * GetColumnSize() - 1)
                number numeratorDegreesOfFreedom = GetColumnSize() - 1
                number denominatorDegreesOfFreedom = 1 / lambda
                number numerator = sumOfWeightedSquares / (GetColumnSize() - 1)
                number denominator = 1 + (2 * (GetColumnSize() - 2) * (lambda / 3))

                number f = numerator / denominator        
                fDistribution:Setup(numeratorDegreesOfFreedom, denominatorDegreesOfFreedom)
                number p = 1.0 - fDistribution:CumulativeDistribution(f)
                number criticalFValue = f //fDistribution:CriticalValue(GetSignificanceLevel())
                number omega_squared = (numeratorDegreesOfFreedom * (f - 1)) / (numeratorDegreesOfFreedom * (f - 1) + totalSize)
        
                // Only necessary to calculate pairwise if the anova null hypothesis has failed or if requested
                Array<CompareGroupsResult> pairwise 
                if p <= GetSignificanceLevel() or mustCalculatePairwise
                    pairwise = ComputePairwiseTests(frame, summaries, 0/*non-pooled*/, denominatorDegreesOfFreedom)
                end

                result:SetDegreesOfFreedomBetweenGroups(numeratorDegreesOfFreedom)
                result:SetDegreesOfFreedomWithinGroups(denominatorDegreesOfFreedom)
                result:SetCriticalValue(criticalFValue)
                result:SetTestStatistic(f)
                result:SetProbabilityValue(p)
                result:SetEffectSize(omega_squared)
                result:SetEffectSizeName("Omega-Squared")
                result:SetPairwiseResults(pairwise)
                result:SetFormalTestName("Welch's One-Way Analysis of Variance")
            end

            result:EqualVariances(equalVariances or assumeEqualVariances)
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            result:SetGroups(groups)
            text factor = ""
            text resultKey = ""
            if UseFactor()
                factor = GetFactorText()
                resultKey = factor + " : " + resultKey
            end
            result:SetFactor(factor)
            results:Add(resultKey, result)
        end
    end

    /*
        This action is a helper action to CompareNIndependentGroups to compute the pairwise results.
    */
    private action ComputePairwiseTests(DataFrame frame, Array<Summarize> summaries, number pooledSD, number degreesOfFreedom) returns Array<CompareGroupsResult>
        Array<CompareGroupsResult> pairwise
        integer k = GetColumnSize()
        number numberOfTestsPerformed = 0
        if useBonferroniCorrection
            numberOfTestsPerformed = math:Factorial(k) / (2 * math:Factorial(k-2)) // #samples choose 2
        end

        i = 0
        repeat while i < k
            j = i + 1
            repeat while j < k
                DataFrameColumn left = frame:GetColumn(GetColumn(i))
                DataFrameColumn right = frame:GetColumn(GetColumn(j))

                Summarize summaryL = summaries:Get(i)
                Summarize summaryR = summaries:Get(j)

                number meanL = summaryL:GetMean()
                number meanR = summaryR:GetMean()
                number varL = summaryL:GetVariance()
                number varR = summaryR:GetVariance()

                number sizeL = left:GetSize()
                number sizeR = right:GetSize()

                Compare2GroupsResult pair
                pair:SetSignificanceLevel(GetSignificanceLevel())
                pair:SetFormat(GetStatisticalFormatting())
                pair:SetGroups(left, right)
                pair:SetDegreesOfFreedom(degreesOfFreedom)

                number t = 0
                number p = 0
                if useBonferroniCorrection
                    tDistribution:Setup(degreesOfFreedom)
                    if equalVariances or assumeEqualVariances 
                        // Use pooled SD 
                        number error = pooledSD * math:SquareRoot(1.0 / sizeL + 1.0 / sizeR)
                        t = (meanL - meanR) / error
                        pair:SetFormalTestName("Pairwise T-test with pooled SD and Bonferroni Correction")
                    else
                        number error = math:SquareRoot(varL / sizeL + varR / sizeR)
                        t = (meanL - meanR) / error
                        pair:SetFormalTestName("Pairwise T-test with non-pooled SD and Bonferroni Correction")
                    end
                    p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
                    p = p * numberOfTestsPerformed 
                    if p > 1
                        p = 1
                    end       
                elseif useTukeyCorrection
                    if equalVariances or assumeEqualVariances
                        // Tukey HSD - use pooled SD 
                        number error = pooledSD * math:SquareRoot((1.0 / sizeL + 1.0 / sizeR) / 2.0)
                        number q = math:AbsoluteValue(meanL - meanR) / error
                        qDistribution:Setup(k, degreesOfFreedom)
                        p = (1 - qDistribution:CumulativeDistribution(q))
                        if p > 1
                            p = 1
                        end 
                        t = q
                        pair:SetFormalTestName("Multiple Comparisons Tukey Post Hoc Analysis")
                    else
                        // Games-Howell - uses Welch's correction as degreesOfFreedom 
                        number error = math:SquareRoot((varL / sizeL + varR / sizeR))
                        number q = math:AbsoluteValue(meanL - meanR) / error
                        qDistribution:Setup(k, degreesOfFreedom)
                        p = (1 - qDistribution:CumulativeDistribution(q * math:SquareRoot(2)))
                        if p > 1
                            p = 1
                        end 
                        t = q
                        pair:SetFormalTestName("Multiple Comparisons Games-Howell Post Hoc Analysis")       
                    end
                else
                    tDistribution:Setup(degreesOfFreedom)
                    if equalVariances or assumeEqualVariances
                        // Use pooled SD 
                        number error = pooledSD * math:SquareRoot(1.0 / sizeL + 1.0 / sizeR)
                        t = (meanL - meanR) / error
                        pair:SetFormalTestName("Pairwise T-test with pooled SD and no family-wise error correction")
                    else
                        number error = math:SquareRoot(varL / sizeL + varR / sizeR)
                        t = (meanL - meanR) / error
                        pair:SetFormalTestName("Pairwise T-test with non-pooled SD and no family-wise error correction")
                    end
                    p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
                    if p > 1
                        p = 1
                    end 
                end
                pair:SetCriticalValue(t)
                pair:SetTestStatistic(t)
                pair:SetProbabilityValue(p)
                pairwise:Add(pair)
                j = j + 1
            end
            i = i + 1
        end
        return pairwise
    end 

    /* 
        One-way repeated measures analysis of variance (ANOVA) for 3 or more dependent groups.
        This action assumes each row in the data set is an individual subject and calculates  

        Assumptions:
            1. Two or more samples:
                If two samples: Best to use a Paired T-Test         > CompareGroups:Compare2DependentGroups
              
            2. Samples are dependent:
                If not dependent: Use a One-Way Anova               > CompareGroups:CompareNIndependentGroups

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Friedman Test                  > CompareRanks:CompareNDependentRanks

            4. Difference between samples have equal variances:
                To test this: Use a Mauchly's Test                  > CompareVariances:CompareDependentVariances
                If not equal: Use Greenhouse-Geisser correction     > CompareGroups:AssumeEqualVariances(false)

        Null hypothesis: The means are equal across all samples.
        Alternative hypothesis: At least one mean is not equal to the others.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("data.csv")
    
        CompareGroups compare 
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:AddColumn(2)
        compare:RepeatedMeasures(true)
        compare:Calculate(frame)

        output compare:GetSummary()
    */
    action CompareNDependentGroups(DataFrame frame)
        if GetFactorSize() > 0
            userRequestedNSampleTest = true
            me:Calculate(frame) // The factor needs to be processed
        else
            if GetColumnSize() < 2
                alert("CompareNDependentGroups must have at least 2 groups.")
            end
    
            number degreesFreedomWithinGroup = 0
            number degreesFreedomBetweenGroup = 0
            number degreesFreedomError = 0
            number sumOfSquaresWithinGroup = 0
            number sumOfSquaresBetweenGroup = 0
            number sumOfSquaresError = 0
            number sumOfSquaresTotal = 0
            number meanSumOfSquaresWithinGroup = 0
            number meanSumOfSquaresBetweenGroup = 0
            number meanSumOfSquaresError = 0

            integer totalSize = 0
            number totalSum = 0
            number totalSumOfSquares = 0
            Array<DataFrameColumn> columns
            Array<NumberColumn> rows
            Array<Summarize> summaries

            DataFrame newFrame
            // Calculate across columns (between groups)
            i = 0
            repeat while i < GetColumnSize()
                DataFrameColumn column = frame:GetColumn(GetColumn(i))
                columns:Add(column)
    
                if column:IsUndefined()
                    alert("Column is undefined.")
                end
    
                if not column:IsNumberColumn() and not column:IsIntegerColumn()
                    alert("Columns must be numerical. " + column:GetHeader() + " is not a numerical column.")
                end
                newFrame:AddColumn(column)

                // Assumption Testing
                if testDistributionAssumption
                    // Run a Shapiro-Wilk's CompareDistributions Test
                    CompareDistributions compare
                    compare:AddColumn(GetColumn(i))
                    compare:CompareDistributionToNormal(frame)
                    if compare:GetProbabilityValue() < GetSignificanceLevel()
                        normalDistribution = false  // Not normal
                    else
                        normalDistribution = true   // Maybe normal
                    end
                end

                Summarize summarize
                column:Calculate(summarize)
                summaries:Add(summarize)
    
                number ss = summarize:GetSumOfSquares() - (summarize:GetSum() * summarize:GetSum() / column:GetSize())
                sumOfSquaresBetweenGroup = sumOfSquaresBetweenGroup + ss
    
                totalSize = totalSize + column:GetSize()
                totalSum = totalSum + summarize:GetSum()
                totalSumOfSquares = totalSumOfSquares + summarize:GetSumOfSquares()
    
                if i = 0 or rows:GetSize() not= column:GetSize()
                    j = 0
                    repeat while j < column:GetSize()
                        NumberColumn col
                        col:Add(column:GetAsNumber(j))
                        rows:Add(col)
                        j = j + 1
                    end
                else
                    j = 0
                    repeat while j < column:GetSize()
                        rows:Get(j):Add(column:GetAsNumber(j))
                        j = j + 1
                    end
                end
    
                i = i + 1
            end

            // Calculate across rows (within groups)
            i = 0
            repeat while i < rows:GetSize()
                Summarize summarize
                rows:Get(i):Calculate(summarize)
                
                sumOfSquaresWithinGroup = sumOfSquaresWithinGroup + (summarize:GetSum() * summarize:GetSum())
                i = i + 1
            end

            // Calculate pairwise paired t-tests with Bonnferroni Correction
            integer k = GetColumnSize()
            number numberOfTestsPerformed = math:Factorial(k) / (2 * math:Factorial(k-2)) // #samples choose 2
            Array<CompareGroupsResult> pairwise
            i = 0
            repeat while i < GetColumnSize()
                j = i + 1
                repeat while j < GetColumnSize()
                    DataFrameColumn left = frame:GetColumn(GetColumn(i))
                    DataFrameColumn right = frame:GetColumn(GetColumn(j))
    
                    DataFrame pairFrame
                    pairFrame:AddColumn(left)
                    pairFrame:AddColumn(right)
    
                    CompareGroups compare
                    compare:AddColumn(0)
                    compare:AddColumn(1)
                    compare:Compare2DependentGroups(pairFrame)
    
                    Compare2GroupsResult pair = cast(Compare2GroupsResult, compare:GetResult())
                    // Apply bonferroni correction
                    if correctFamilyWiseError
                        number newP = pair:GetProbabilityValue() 
                        if useBonferroniCorrection
                            newP = newP * numberOfTestsPerformed
                        end
                        if newP > 1
                            newP = 1
                        end
                        pair:SetProbabilityValue(newP)
                        pair:SetFormalTestName("Pairwise Paired T-test with Bonferroni Correction")
                    else
                        pair:SetFormalTestName("Pairwise Paired T-test with no family-wise error correction")
                    end
                    pairwise:Add(pair)
                    j = j + 1
                end
                i = i + 1
            end

            // Calculate sum of squares
            sumOfSquaresTotal = totalSumOfSquares - (totalSum * totalSum / totalSize) 
            sumOfSquaresBetweenGroup = sumOfSquaresTotal - sumOfSquaresBetweenGroup                                  
            sumOfSquaresWithinGroup = (sumOfSquaresWithinGroup/GetColumnSize()) - (totalSum * totalSum / totalSize) 
            sumOfSquaresError = sumOfSquaresTotal - sumOfSquaresBetweenGroup - sumOfSquaresWithinGroup
    
            // Calculate degrees of freedom
            degreesFreedomBetweenGroup = GetColumnSize() - 1                        // number of groups - 1 
            degreesFreedomWithinGroup = totalSize/(degreesFreedomBetweenGroup+1)-1  // number of subjects - 1
            degreesFreedomError = degreesFreedomBetweenGroup*degreesFreedomWithinGroup
    
            // Calculate mean sum of squares 
            meanSumOfSquaresBetweenGroup = sumOfSquaresBetweenGroup / degreesFreedomBetweenGroup
            meanSumOfSquaresWithinGroup = sumOfSquaresWithinGroup / degreesFreedomWithinGroup
            meanSumOfSquaresError = sumOfSquaresError / degreesFreedomError
    
            // Calculate the standard f statistic assuming sphericity
            number f = meanSumOfSquaresBetweenGroup / meanSumOfSquaresError        
            fDistribution:Setup(degreesFreedomBetweenGroup, degreesFreedomError)
            number p = 1.0 - fDistribution:CumulativeDistribution(f)

            CompareNGroupsResult result
            if testVarianceAssumption
                // Assumption Testing
                // If P-value ≤ α, then run a Mauchly's CompareVariances test 
                    // This is not necessary if this test is already not significant with standard f
                    if p <= GetSignificanceLevel()
                    newFrame:AddSelectedColumnRange(0, newFrame:GetSize()-1)
        
                    CompareVariances compare
                    newFrame:GetSelection():CopyTo(cast(ColumnInput, compare))
                    compare:RepeatedMeasures(true)
                    compare:Calculate(newFrame)
        
                    CompareVariancesResult vResult = compare:GetResult()
                    vResult:SetFormalTestName("Mauchly's test")
                    number correction = vResult:GetCorrection()
        
                    // Implement correction then recalculate f and p
                    degreesFreedomBetweenGroup = degreesFreedomBetweenGroup * correction
                    degreesFreedomError = degreesFreedomError * correction
        
                    meanSumOfSquaresBetweenGroup = sumOfSquaresBetweenGroup / degreesFreedomBetweenGroup
                    meanSumOfSquaresError = sumOfSquaresError / degreesFreedomError
            
                    f = meanSumOfSquaresBetweenGroup / meanSumOfSquaresError 
                    fDistribution:Setup(degreesFreedomBetweenGroup, degreesFreedomError)
                    p = 1.0 - fDistribution:CumulativeDistribution(f)
        
                    if correction not= 1
                        result:SetCompareVariancesResult(vResult)
                        equalVariances = false  // Significantly different
                    else
                        equalVariances = true   // Approximately equal
                    end
                end
            end

            number criticalFValue = f//fDistribution:CriticalValue(GetSignificanceLevel())
            number eta = sumOfSquaresBetweenGroup / totalSumOfSquares
    
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            result:RepeatedMeasures(true)
            result:SetCriticalValue(criticalFValue)
            result:SetTestStatistic(f)
            result:SetProbabilityValue(p)
            result:EqualVariances(equalVariances or assumeEqualVariances)
            result:SetSumOfSquaresBetweenGroups(sumOfSquaresBetweenGroup)
            result:SetDegreesOfFreedomBetweenGroups(degreesFreedomBetweenGroup)
            result:SetMeanSumOfSquaresBetweenGroups(meanSumOfSquaresBetweenGroup)
            result:SetSumOfSquaresWithinGroups(sumOfSquaresWithinGroup)
            result:SetDegreesOfFreedomWithinGroups(degreesFreedomWithinGroup)
            result:SetMeanSumOfSquaresWithinGroups(meanSumOfSquaresWithinGroup)
            result:SetSumOfSquaresError(sumOfSquaresError)
            result:SetDegreesOfFreedomError(degreesFreedomError)
            result:SetMeanSumOfSquaresError(meanSumOfSquaresError)
            result:SetFormalTestName("Repeated Measures Analysis of Variance")
            result:SetEffectSize(eta)
            result:SetEffectSizeName("Eta-Squared")
            result:SetGroups(columns)
            result:SetPairwiseResults(pairwise)
            text factor = ""
            text resultKey = ""
            if UseFactor()
                factor = GetFactorText()
                resultKey = factor + " : " + resultKey
            end
            result:SetFactor(factor)
            results:Add(resultKey, result)
        end
    end

    /*
        This action represents a two sample t-test on two columns of data.

        Assumptions:
            1. Two samples:
                If more than two samples: Use a One-Way Anova       > CompareGroups:CompareNIndependentGroups
              
            2. Samples are independent:
                If not independent: Use a Paired T-Test             > CompareGroups:Compare2DependentGroups

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Mann-Whiteney U-Test           > CompareRanks:Compare2IndependentRanks

            4. Samples have equal variances:
                To test this: Use a Levene's Test                   > CompareVariances:CompareIndependentVariances
                If not equal: Use Welch's T-Test                    > CompareGroups:AssumeEqualVariances(false)

        Null hypothesis: The two means are equal
        Alternative hypothesis: The two means are not equal

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("data.csv")
    
        CompareGroups compare 
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:Calculate(frame)

        output compare:GetSummary()
    */
    action Compare2IndependentGroups(DataFrame frame)
        if GetFactorSize() > 0
            me:Calculate(frame) // The factor needs to be processed
        else
            if GetColumnSize() < 2
                alert("Compare2IndependentGroups must have 2 groups.")
            end

            integer i = 0
            repeat while i < GetColumnSize()
                integer j = i + 1
                repeat while j < GetColumnSize()
                    DataFrameColumn left = frame:GetColumn(GetColumn(i))
                    DataFrameColumn right = frame:GetColumn(GetColumn(j))

                    if left = undefined or right = undefined
                        alert("Column is undefined.")
                    end
            
                    if not left:IsNumberColumn() and not left:IsIntegerColumn()
                        alert("Columns must be numerical. " + left:GetHeader() + " is not a numerical column.")
                    end
            
                    if not right:IsNumberColumn() and not right:IsIntegerColumn()
                        alert("Columns must be numerical. " + right:GetHeader() + " is not a numerical column.")
                    end
            
                    if left:GetSize() < 2 or right:GetSize() < 2
                        alert("Columns must have 2 or more entries. Not enough data for test to be calculated.")
                    end

                    // Assumption Testing
                    if testDistributionAssumption
                        // Run a Shapiro-Wilk's CompareDistributions Test
                        CompareDistributions compare
                        compare:AddColumn(GetColumn(i))
                        compare:CompareDistributionToNormal(frame)
                        if compare:GetProbabilityValue() < GetSignificanceLevel()
                            normalDistribution = false  // Not normal
                        else
                            normalDistribution = true   // Maybe normal
                        end
                    end

                    // Assumption Testing
                    if testVarianceAssumption
                        // Run a Levene's CompareVariances test 
                        CompareVariances compare
                        i = 0
                        repeat while i < GetColumnSize()
                            compare:AddColumn(GetColumn(i))
                            i = i + 1
                        end
                        compare:CompareIndependentVariances(frame)
                        if compare:GetProbabilityValue() < GetSignificanceLevel()
                            equalVariances = false  // Significantly different
                        else
                            equalVariances = true   // Approximately equal
                        end
                    end

                    Compare2GroupsResult result
                    result:SetSignificanceLevel(GetSignificanceLevel())
                    result:SetFormat(GetStatisticalFormatting())
                    result:SetGroups(left, right)

                    number mean1 = result:GetMean1()
                    number mean2 = result:GetMean2()
                    number var1 = result:GetVariance1()
                    number var2 = result:GetVariance2()
                    number size1 = left:GetSize()
                    number size2 = right:GetSize()

                    number t = 0
                    number df = 0
                    if equalVariances or assumeEqualVariances
                        number pooledVar = ((size1  - 1) * var1 + (size2 - 1) * var2 ) / (size1 + size2 - 2)
                        t = (mean1 - mean2) / (math:SquareRoot(pooledVar * ((1 / size1) + (1 / size2))))
                        df = size1 + size2 - 2
                        result:SetFormalTestName("Two Sample T-test")
                    else
                        t = (mean1 - mean2) / (math:SquareRoot((var1 / size1) + (var2 / size2)))
                        df = DegreesOfFreedom(var1, var2, size1, size2)
                        result:SetFormalTestName("Welch's Two Sample T-test")
                    end
                    tDistribution:Setup(df)
                    number p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
                    number criticalTValue = t//tDistribution:CriticalValue(GetSignificanceLevel())
    
                    number cohensD = math:SquareRoot((var1 + var2) / 2.0)
                    cohensD = (mean1 - mean2) / cohensD
        
                    text factor = ""
                    text resultKey = left:GetHeader()+" & "+right:GetHeader()
                    if UseFactor()
                        factor = GetFactorText()
                        resultKey = factor + " : " + resultKey
                    end
                    if not results:HasKey(resultKey)
                        result:SetCriticalValue(criticalTValue) 
                        result:SetTestStatistic(t)
                        result:SetDegreesOfFreedom(df)
                        result:SetProbabilityValue(p)
                        result:SetFactor(factor)
                        result:Paired(false)
                        result:EqualVariances(equalVariances or assumeEqualVariances)
                        result:SetEffectSize(cohensD)
                        result:SetEffectSizeName("Cohen's D")
                        result:SetFormat(GetStatisticalFormatting())
                        results:Add(resultKey, result)
                    end
                    j = j + 1
                end
                i = i + 1
            end
        end
    end

    /*
        This action represents a two sample paired t-test.

        Assumptions:
            1. Two samples:
                If more than two samples: Use a Repeated Measures Anova > CompareGroups:CompareNDependentGroups
              
            2. Samples are dependent:
                If not dependent: Use a Two-Sample T-Test               > CompareGroups:Compare2IndependentGroups

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test                   > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Wilcoxon Signed-Ranks Test         > CompareRanks:Compare2DependentRanks

        Null hypothesis: The difference mean is equal to given (default 0) mean
        Alternative hypothesis: The difference mean is not equal to given (default 0) mean

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("data.csv")
    
        CompareGroups compare 
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:Paired(true)
        compare:SetMean(10)
        compare:Calculate(frame)

        output compare:GetSummary()
    */
    action Compare2DependentGroups(DataFrame frame)
        if GetFactorSize() > 0
            me:Calculate(frame) // The factor needs to be processed
        else
            if GetColumnSize() < 2
                alert("Compare2DependentGroups must have 2 groups.")
            end

            integer i = 0
            repeat while i < GetColumnSize()
                integer j = i + 1
                repeat while j < GetColumnSize()
                    DataFrameColumn left = frame:GetColumn(GetColumn(i))
                    DataFrameColumn right = frame:GetColumn(GetColumn(j))
    
                    if left = undefined or right = undefined
                        alert("Column is undefined.")
                    end
            
                    if not left:IsNumberColumn() and not left:IsIntegerColumn()
                        alert("Columns must be numerical. " + left:GetHeader() + " is not a numerical column.")
                    end
            
                    if not right:IsNumberColumn() and not right:IsIntegerColumn()
                        alert("Columns must be numerical. " + right:GetHeader() + " is not a numerical column.")
                    end
            
                    if left:GetSize() < 2 or right:GetSize() < 2
                        alert("Columns must have 2 or more entries. Not enough data for test to be calculated.")
                    end

                    if left:GetSize() not= right:GetSize()
                        alert("Columns must be the same size. " + left:GetHeader() + " is a different size than "+ right:GetHeader() + ".")
                    end

                    // Assumption Testing
                    if testDistributionAssumption
                        // Run a Shapiro-Wilk's CompareDistributions Test
                        CompareDistributions compare
                        compare:AddColumn(GetColumn(i))
                        compare:CompareDistributionToNormal(frame)
                        if compare:GetProbabilityValue() < GetSignificanceLevel()
                            normalDistribution = false  // Not normal
                        else
                            normalDistribution = true   // Maybe normal
                        end
                    end
                    
                    NumberColumn numLeft = left:ConvertToNumberColumn()
                    NumberColumn numRight = right:ConvertToNumberColumn()
                    NumberColumn difference = numLeft:Subtract(numRight)
    
                    DataFrame newFrame
                    newFrame:AddColumn(difference)
    
                    CompareGroups compare
                    compare:AddColumn(0)
                    compare:SetMean(userMean)
                    compare:CompareGroupToMean(newFrame)
                    Compare1GroupResult res = cast(Compare1GroupResult, compare:GetResult())

                    text factor = ""
                    text resultKey = left:GetHeader()+" & "+right:GetHeader()
                    if UseFactor()
                        factor = GetFactorText()
                        resultKey = factor + " : " + resultKey
                    end
                    if not results:HasKey(resultKey)
                        Compare2GroupsResult result
                        result:SetSignificanceLevel(GetSignificanceLevel())
                        result:SetFormat(GetStatisticalFormatting())
                        result:SetGroups(left, right)
                        result:SetDifferenceMean(res:GetMean1())
                        result:SetDifferenceVariance(res:GetVariance1())
                        result:SetUserMean(userMean)
                        result:SetCriticalValue(res:GetCriticalValue())
                        result:SetTestStatistic(res:GetTestStatistic())
                        result:SetDegreesOfFreedom(res:GetDegreesOfFreedom())
                        result:SetProbabilityValue(res:GetProbabilityValue())
                        result:SetFactor(factor)
                        result:SetEffectSize(res:GetEffectSize())
                        result:SetEffectSizeName(res:GetEffectSizeName())
                        result:SetFormalTestName("Paired T-test")
                        result:Paired(true)
                        results:Add(resultKey, result)
                    end
                    j = j + 1
                end
                i = i + 1
            end
        end
    end

    /* 
        This is a one-sample t-test against a given mean (default is 0)

        Assumptions:
            1. One sample:
                If more than one sample: Use a Paired T-Test        > CompareGroups:Compare2DependentGroups

            3. Sample is normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Wilcoxon Signed-Ranks Test     > CompareRanks:CompareRanksToMedian

        Null hypothesis: The mean is equal to given (default 0) mean
        Alternative hypothesis: The mean is not equal to given (default 0) mean

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("data.csv")
    
        CompareGroups compare 
        compare:AddColumn(0)
        compare:SetMean(10)
        compare:Calculate(frame)

        output compare:GetSummary()
    */
    action CompareGroupToMean(DataFrame frame)
        if GetFactorSize() > 0
            me:Calculate(frame) // The factor needs to be processed
        else
            if GetColumnSize() < 1
                alert("CompareGroupToMean must have at least 1 group.")
            end

            i = 0
            repeat while i < GetColumnSize()
                DataFrameColumn column = frame:GetColumn(GetColumn(i))
    
                if column = undefined
                    alert("Column is undefined.")
                end
    
                if not column:IsNumberColumn() and not column:IsIntegerColumn()
                    alert("Columns must be numerical. " + column:GetHeader() + " is not a numerical column.")
                end
    
                if column:GetSize() < 2
                    alert("Columns must have 2 or more entries. Not enough data for comparison to be calculated.")
                end

                // Assumption Testing
                if testDistributionAssumption
                    // Run a Shapiro-Wilk's CompareDistributions Test
                    CompareDistributions compare
                    compare:AddColumn(GetColumn(i))
                    compare:CompareDistributionToNormal(frame)
                    if compare:GetProbabilityValue() < GetSignificanceLevel()
                        normalDistribution = false  // Not normal
                    else
                        normalDistribution = true   // Maybe normal
                    end
                end
    
                Compare1GroupResult result
                result:SetSignificanceLevel(GetSignificanceLevel())
                result:SetFormat(GetStatisticalFormatting())
                result:SetGroups(column, undefined)
    
                number mean = result:GetMean1()
    
                number variance = result:GetVariance1()
    
                number size = column:GetSize()
    
                number cohensD = math:SquareRoot(variance)
                cohensD = (mean - userMean) / cohensD
       
                number t = (mean - userMean) / (math:SquareRoot(variance / size))
                number df = size - 1
                tDistribution:Setup(df)
                number p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
                number criticalTValue = t//tDistribution:CriticalValue(GetSignificanceLevel())
    
                text factor = ""
                text resultKey = column:GetHeader()
                if UseFactor()
                    factor = GetFactorText()
                    resultKey = factor + " : " + resultKey
                end
                if not results:HasKey(resultKey)
                    result:SetCriticalValue(criticalTValue)
                    result:SetTestStatistic(t)
                    result:SetProbabilityValue(p)
                    result:SetDegreesOfFreedom(df)
                    result:SetFactor(factor)
                    result:SetMean2(userMean)
                    result:SetEffectSize(cohensD)
                    result:SetEffectSizeName("Cohen's D")
                    result:SetFormalTestName("One Sample T-test")
                    result:SetFormat(GetStatisticalFormatting())
                    results:Add(resultKey, result)
                end
                i = i + 1
            end
        end
    end

    /* Computes approximate degrees of freedom for 2-sample t-test in Compare2Groups */
    private action DegreesOfFreedom(number variance1, number variance2, number size1, number size2) returns number
        return (((variance1 / size1) + (variance2 / size2)) * ((variance1 / size1) + (variance2 / size2))) /
        ((variance1 * variance1) / (size1 * size1 * (size1 - 1.0)) + (variance2 * variance2) /
                (size2 * size2 * (size2 - 1.0)))
    end

    /* Used in 1-sample and 2-sample (paired) tests */
    action SetMean(number mean)
        me:userMean = mean
    end

    /* Used in 2-sample tests */
    action Paired(boolean paired)
        me:paired = paired
    end

    /* Used in N-sample tests */
    action RepeatedMeasures(boolean repeatedMeasures)
        me:repeatedMeasures = repeatedMeasures
    end

    /* Used in 2-sample and N-sample tests */
    action AssumeEqualVariances(boolean assume)
        assumeEqualVariances = assume
        if assume
            testVarianceAssumption = false
        end
    end

    /* Used in 2-sample and N-sample tests */
    action TestVarianceAssumption
        testVarianceAssumption = true
        assumeEqualVariances = false
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action AssumeNormalDistribution(boolean assume)
        assumeNormalDistribution = true
        if assume
            testDistributionAssumption = false
        end
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action TestDistributionAssumption
        testDistributionAssumption = true
        assumeNormalDistribution = false
    end

    /* This action will set all of the assumption tests to be calculated */
    action TestAllAssumptions
        TestVarianceAssumption()
        TestDistributionAssumption()
    end

    /* Used in N-sample tests */
    /* Bonferroni method is the default if another is not selected */
    action CorrectFamilyWiseError(boolean correctFamilyWiseError)
        me:correctFamilyWiseError = correctFamilyWiseError
        if not useTukeyCorrection
            useBonferroniCorrection = correctFamilyWiseError
        end
    end

    /* Choose bonferroni method as correction for N-sample pairwise tests */
    action UseBonferroniCorrection
        useBonferroniCorrection = true
        correctFamilyWiseError = true
        useTukeyCorrection = false
    end

    /* Choose tukey method as correction for independent N-sample pairwise tests */
    action UseTukeyCorrection
        useTukeyCorrection = true
        useBonferroniCorrection = false
        correctFamilyWiseError = true
    end

    /* Force calculation of pairwise results in N-sample tests. */
    /* By default, these are only calculated if the null hypothesis of the test is failed */
    action MustCalculatePairwiseTests(boolean mustCalculatePairwise)
        me:mustCalculatePairwise = mustCalculatePairwise
    end

    /*
        This returns the probability if only one result exists.

        Attribute: Returns the P-Value. 
    */
    action GetProbabilityValue returns number
        return GetResult():GetProbabilityValue()
    end

    /*
        This returns the degrees of freedom if only one result exists.

        Attribute: Returns the Degrees of Freedom. 
    */
    action GetDegreesOfFreedom returns number
        return GetResult():GetDegreesOfFreedom()
    end

    /*
        This returns the test statistic if only one result exists.

        Attribute: Returns the test statistic. 
    */
    action GetTestStatistic returns number
        return GetResult():GetTestStatistic()
    end

    /*
        This returns the effect size if only one result exists.

        Attribute: Returns the effect size. 
    */
    action GetEffectSize returns number
        return GetResult():GetEffectSize()
    end

    /*
        This returns the pairwise results if only one result exists.
        Pairwise results are only calculated in N-sample tests, 
        otherwise this will return undefined.

        Attribute: Returns the pairwise results. 
    */
    action GetPairwiseResults returns Array<CompareGroupsResult>
        return GetResult():GetPairwiseResults()
    end

    /*
        This returns a result if only one exists.

        Attribute: Returns the CompareGroupsResult object
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("Data/Data.csv")

        CompareGroups compare
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:Calculate(frame)
        
        CompareGroupsResult result = compare:GetResult()
    */
    action GetResult returns CompareGroupsResult
        if results:GetSize() = 1
            return results:GetValueIterator():Next()
        else
            alert("There is more than one test result, use GetResults() for an array of all results")
        end
    end

    /*
        Attribute: Returns an array of CompareGroupsResult objects
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareGroups compare
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:AddColumn(2)
        frame:Calculate(compare)

        Array<CompareGroupsResult> results = compare:GetResults()
    */
    action GetResults returns Array<CompareGroupsResult>
        return results:CopyToValueArray()
    end

    /*
        Attribute: Returns a list of the important statistics of the test
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareGroups compare
        compare:Add(0)
        compare:Add(1)
        frame:Calculate(compare)

        output compare:GetSummary()
    */
    action GetSummary returns text
        text summary = ""
        text lf = summary:GetLineFeed()
        Iterator<CompareGroupsResult> i = results:GetValueIterator()
        CompareGroupsResult result 
        repeat while i:HasNext()
            result = i:Next()

            summary = summary + lf
            summary = summary + result:GetSummary()
            summary = summary + lf
        end

        return summary
    end

    /*
        This action summarizes the results and places them into formal academic language, in 
        APA format.
        For more information: https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf

        Attribute: Returns a condensed formal result of the test
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareGroups
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareGroups compare
        compare:Add(0)
        compare:Add(1)
        frame:Calculate(compare)

        output compare:GetFormalSummary()
    */
    action GetFormalSummary returns text
        text summary = ""
        text lf = summary:GetLineFeed()
        Iterator<CompareGroupsResult> i = results:GetValueIterator()
        CompareGroupsResult result 
        repeat while i:HasNext()
            result = i:Next()

            summary = summary + lf
            summary = summary + result:GetFormalSummary()
            summary = summary + lf
        end

        return summary
    end
end