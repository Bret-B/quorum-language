package Libraries.Compute.Statistics.Tests

use Libraries.Compute.Statistics.Tests.StatisticalTest
use Libraries.Compute.Statistics.DataFrameCalculation
use Libraries.Compute.Statistics.DataFrameColumn
use Libraries.Compute.Statistics.DataFrame
use Libraries.Containers.Array
use Libraries.Compute.Statistics.Calculations.Summarize
use Libraries.Compute.Statistics.Reporting.StatisticsFormatting
use Libraries.Containers.HashTable
use Libraries.Compute.Statistics.Columns.NumberColumn
use Libraries.Compute.Statistics.Reporting.CompareCountsResult
use Libraries.Compute.Statistics.Distributions.ClassificationDistribution
use Libraries.Containers.Iterator
use Libraries.Compute.Math
use Libraries.Compute.Matrix
use Libraries.Compute.Vector
use Libraries.Compute.Statistics.Transforms.CrossTab
use Libraries.System.File

/*
This class implements several proportion comparison hypothesis tests. 
In addition to the comparison tests, this class can be directed to run any assumption tests and post-hoc tests 
that are typically accompanied with the given comparison test. Controls for specific post hoc analysis 
approaches or corrections can be used via this class as well.
See the INFORMATION comment block at the bottom of this class for more information about each test.
For more information: https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test

Attribute: Author Hannah Stabler
Attribute: Example

use Libraries.Compute.Statistics.DataFrame
use Libraries.Compute.Statistics.Tests.CompareCounts

DataFrame frame
frame:Load("Data/Data.csv")
frame:AddSelectedColumnRange(0,2)

CompareCounts compare = frame:CompareCounts()
output compare:GetSummary()   
*/

class CompareCounts is StatisticalTest
    private Math math
    private ClassificationDistribution distribution // Distribution to calculate the p-value from test-statistic and degrees of freedom

    // TEST AUTO-SELECTION ELEMENTS
    private boolean needToSelectTest = true         // Flag to let this class auto-select a test based on given data
    private boolean needToProcessData = true        // Flag to let tell this class to process the selected data     
    private boolean defaultPairwiseComparisons = true   // Flag to test pairwise tests if several-sample test is significant
    private boolean defaultAssumptionTests = true       // Flag to test assumption tests if applicable

    // DESIGN ELEMENTS AND CONTROLS
    private ExperimentalDesign design = undefined   // Design object to hold and process various selections and data formats      
    private integer numberOfInputVariables = 0      // Number of independent variables (IVs) selected
    private integer numberOfOutputVariables = 0     // Number of dependent variables (DVs) selected
    private boolean factorial = false               // Flag for multiple independent variables (IVs)
    private boolean multivariate = false            // Flag for multiple dependent variables (DVs)
    private boolean repeated = false                // Flag for paired or repeated measures tests    
    
    // PAIRWISE USER CONTROLS
    private boolean correctFamilyWiseError = true   // Family-wise correction is applied in several-sample pairwise tests 
    private boolean useStrictCorrection = true      // Procedure to be applied in pairwise tests (corrects for p-value using Bonferroni correction)
    private boolean useLenientCorrection = false    // Procedure to be applied in pairwise tests (corrects for p-value inherently when applicable)
    private boolean useFittedApproach = false       // Conducts comparisons using the fitted several-sample test results
    private boolean useUnfittedApproach = true      // Conducts comparisons using individual pariwise two-sample tests

    // TEST USER CONTROLS
    private boolean useContinuityCorrection = false // A flag for continuity correction for approximation error (only applicable for 2x2 tests)
    private boolean approximationWarning = false    // A flag to let the user know approximation may be incorrect due to low counts.
    private boolean goodnessOfFit = false           // A flag if requesting a goodness of fit test (default for one sample).
    private boolean testAssumptionsTests = true     // A flag to request assumption tests manually if applicable
    private boolean testPairwiseComparisons = false // A flag to request pairwise tests regardless of significance in several-sample test
    private boolean skipPairwiseComparisons = false // A flag to skip pairwise tests regardless of significance in several-sample test

    // TEST RESULTS
    private Array <CompareCountsResult> results     // An array of results, typically only one result except in pairwise tests

    action Calculate(DataFrame frame) 
        results:Empty()

        if design = undefined
            ExperimentalDesign newDesign
            design = newDesign
        end
          
        if design:GetDesignFrame() = undefined
            design:RepeatedMeasures(repeated)
            design:Transform(frame)
        end 
        repeated = design:RepeatedMeasures()    // This will override the boolean if a within factor is or isn't specified.

        numberOfInputVariables = design:GetBetweenSubjectsFactors():GetSize() + design:GetWithinSubjectsFactors():GetSize()
        numberOfOutputVariables = design:GetDependentVariables():GetSize()

        if numberOfInputVariables > 0 and numberOfOutputVariables > 1
            multivariate = true
        else
            multivariate = false
        end

        if numberOfInputVariables > 1
            factorial = true
        else
            factorial = false
        end

        needToProcessData = false
        if needToSelectTest
            SelectTest(design:GetDesignFrame())
        end
    end
     
    private action RunTest(DataFrame frame)
        SelectTest(frame)
    end

    private action SelectTest(DataFrame frame)
        needToProcessData = false

        if multivariate
            alert("A multivariate CompareCounts test with multiple dependent variables is not supported yet.")
        end
        if factorial
            alert("A factorial CompareCounts test with multiple independent variables is not supported yet.")
        end

        integer numberOfSamples = 0
        if repeated
            numberOfSamples = design:GetNumberOfMeasurements()
        else
            numberOfSamples = design:GetNumberOfIndependentGroups()
        end
        if numberOfSamples < 1
            alert("A CompareCounts calculation must include at least one sample.")
        end

        if numberOfSamples = 1
            GoodnessOfFit(frame)
        else
            if repeated
                CompareSeveralRelatedCounts(frame)
            else
                CompareSeveralCounts(frame)
            end
        end
    end

    /*
        This action represents a McNemar-Bowker Test of Symmetry on three or more columns of data.
        It calculates the observed values by counting the frequencies of unique items.
        It then calculates the expected counts and compares the two to get the x2 value.

        H0: The two variables are independent.
        Ha: The two variables are not independent.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumns(0)
        frame:AddSelectedColumns(1)
    
        CompareCounts compare = frame:CompareRelatedCounts()
        output compare:GetSummary()
    */
    action CompareSeveralRelatedCounts(DataFrame frame)
        repeated = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if not repeated
            CompareSeveralCounts(frame)
        end

        Array<text> ivs = design:GetWithinSubjectsFactors()
        Array<text> dvs = design:GetDependentVariables()        
        number numberOfInputCategories = design:GetNumberOfMeasurements()
        number numberOfOutputCategories = 0

        Array<text> sources
        source = ivs:Get(0)
        sources:Add(source)
        DataFrame observed
        if design:GetGroupsFrame():GetSize() = 2
            // The cross tab should have the same categories on rows and cols
            CrossTab tab
            tab:AddColumn(0)
            tab:AddColumn(1)
            tab:FullRowsAndColumns(true)
            observed = tab:Transform(design:GetGroupsFrame()) 
            numberOfOutputCategories = observed:GetSize()-1 // The first column is row headers
        else
            numberOfOutputCategories = design:GetDesignFrame():GetColumn(dvs:Get(0)):Copy(true,true):GetSize()
        end
      
        CompareCountsResult result
        text testName = ""
        number x2 = 0 
        number df = 0
        if numberOfInputCategories = 2 and numberOfOutputCategories = 2
            x2 = McNemar(observed, source, result) 
            df = 1
            testName = "McNemar's Test For Symmetry"
        elseif numberOfInputCategories = 2 and numberOfOutputCategories >= 3
            x2 = McNemarBowker(observed, source, result)
            df = numberOfOutputCategories * (numberOfOutputCategories - 1) / 2.0
            testName = "McNemar-Bowker's Test Of Symmetry"
        elseif numberOfInputCategories >= 3 and numberOfOutputCategories = 2
            x2 = Cochran(observed, source, result)
            df = numberOfInputCategories-1 
            testName = "Cochran's Q Test"         
        else
            alert("A CompareCounts test using 3 or more input categories and 3 or more output categories is not available yet. Formal Test: Log-Linear Analysis")
        end
        distribution:Setup(df)
        number p = 1.0 - distribution:CumulativeDistribution(x2)

        result:SetGroupsFrame(design:GetGroupsFrame())
        result:SetSources(sources)
        result:SetObserved(observed)
        result:SetTestStatistic(source, "X2", x2)
        result:SetDegreesOfFreedom(source, "X2", df)
        result:SetProbabilityValue(source, "X2", p)
        result:SetInformation(source, "X2", x2)
        result:SetInformation(source, "p", p)
        result:SetExperimentalDesign(design)
        result:SetFormalTestName(testName)
        if approximationWarning
            result:SetApproximationWarningFlag(true)
            approximationWarning = false //reset
        end
        if design:GetGroupsFrame():GetSize() > 2 and (p <= GetSignificanceLevel() or testPairwiseComparisons) and not skipPairwiseComparisons
            // Pairwise tests are only necessary if the test is significant
            CompareCountsPairwise compare
            compare:SetSignificanceLevel(GetSignificanceLevel())
            compare:SetStatisticalFormatting(GetStatisticalFormatting())
            compare:UseLenientCorrection(useLenientCorrection)
            compare:UseStrictCorrection(useStrictCorrection)
            compare:SetExperimentalDesign(design)
            compare:Calculate(result)
            result:SetPairwiseResults(compare:GetResults())
            result:SetPairwiseTest(compare)
        end
        results:Add(result)
    end


    /*
        This action represents a chi-squared test of independence test on two or more columns of data.
        It calculates the observed values by counting the frequencies of unique items.
        It then calculates the expected counts and compares the two to get the x2 value.

        H0: The two variables are independent.
        Ha: The two variables are not independent.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumns(0)
        frame:AddSelectedColumns(1)
    
        CompareCounts compare = frame:CompareCounts()
        output compare:GetSummary()
    */
    action CompareSeveralCounts(DataFrame frame)
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if repeated
            CompareSeveralRelatedCounts(frame)
        end
        Array<text> ivs = design:GetBetweenSubjectsFactors()
        Array<text> dvs = design:GetDependentVariables()

        DataFrameColumn iv = design:GetDesignFrame():GetColumn(ivs:Get(0))
        DataFrameColumn dv = design:GetDesignFrame():GetColumn(dvs:Get(0))
        DataFrame observed = CalculateObserved(iv, dv)
        DataFrame expected = CalculateExpectedFromObserved(observed)
        integer rows = observed:GetColumn(0):GetSize()
        integer cols = observed:GetColumns():GetSize()-1
        number x2 = ChiSquare(observed, expected)  
        number df = (rows-1)*(cols-1)
        distribution:Setup(df)
        number p = 1.0 - distribution:CumulativeDistribution(x2)
        number v = math:SquareRoot(x2 / (design:GetNumberOfSubjects() * df))

        Array<text> sources
        text source = ivs:Get(0)
        sources:Add(source)
        CompareCountsResult result
        result:SetGroupsFrame(design:GetGroupsFrame())
        result:SetSources(sources)
        result:SetObserved(observed)
        result:SetExpected(expected)
        result:SetResiduals(CalculateResiduals(observed, expected))
        result:SetAdjustedResiduals(CalculateAdjustedResiduals(observed, expected))
        result:SetTestStatistic(source, "X2", x2)
        result:SetDegreesOfFreedom(source, "X2", df)
        result:SetProbabilityValue(source, "X2", p)
        result:SetInformation(source, "X2", x2)
        result:SetInformation(source, "p", p)
        result:SetEffectSize(source, "Cramer's V", v)
        result:SetVariable1(iv:GetHeader())
        result:SetVariable2(dv:GetHeader())
        result:SetFactor(ivs:Get(0))
        result:SetSampleSize(design:GetNumberOfSubjects())
        result:SetExperimentalDesign(design)
        result:SetFormalTestName("Pearson's Chi-Squared Test of Independence")
        if approximationWarning
            result:SetApproximationWarningFlag(true)
            approximationWarning = false //reset
        end
        if design:GetGroupsFrame():GetSize() > 2 and (p <= GetSignificanceLevel() or testPairwiseComparisons) and not skipPairwiseComparisons
            // Pairwise tests are only necessary if the test is significant
            CompareCountsPairwise compare
            compare:SetSignificanceLevel(GetSignificanceLevel())
            compare:SetStatisticalFormatting(GetStatisticalFormatting())
            compare:UseLenientCorrection(useLenientCorrection)
            compare:UseStrictCorrection(useStrictCorrection)
            compare:SetExperimentalDesign(design)
            compare:Calculate(result)
            result:SetPairwiseResults(compare:GetResults())
            result:SetPairwiseTest(compare)
        end
        results:Add(result)
    end

    /*
        This action represents a goodness of fit chi-squared test on a selected columns of data.
        It calculates the observed values by counting the frequencies of unique items.
        It then calculates the expected counts (expecting an equal distribution) and compares 
        the two to get the x2 value.

        H0: The population fits a uniform distribution.
        Ha: The population does not fit a uniform distribution.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumns(0)
    
        CompareCounts compare = frame:CompareCounts()
        output compare:GetSummary()
    */
    action GoodnessOfFit(DataFrame frame)
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected manually
            me:Calculate(frame)
        end

        goodnessOfFit = true
        integer i = 0
        repeat while i < design:GetGroupsFrame():GetSize()
            DataFrame observed = CalculateObserved(design:GetGroupsFrame():GetColumn(i))
            DataFrame expected = CalculateExpectedFromObserved(observed)
            integer rows = observed:GetColumn(0):GetSize()
            integer cols = observed:GetColumns():GetSize()
            number x2 = ChiSquare(observed:GetColumn(1), expected:GetColumn(1))  
            number df = (rows-1)*(cols-1)
            distribution:Setup(df)
            number p = 1.0 - distribution:CumulativeDistribution(x2)
            number v = math:SquareRoot(x2 / (design:GetNumberOfSubjects() * df))
    
            text variable = design:GetGroupsFrame():GetColumn(i):GetHeader()

            Array<text> sources
            text source = variable
            sources:Add(source)
            CompareCountsResult result
            result:SetGroupsFrame(design:GetGroupsFrame())
            result:SetGoodnessOfFit(true)
            result:SetSources(sources)
            result:SetObserved(observed)
            result:SetExpected(expected)
            result:SetResiduals(CalculateResiduals(observed, expected))
            result:SetAdjustedResiduals(CalculateAdjustedResiduals(observed, expected))
            result:SetTestStatistic(source, "X2", x2)
            result:SetDegreesOfFreedom(source, "X2", df)
            result:SetProbabilityValue(source, "X2", p)
            result:SetInformation(source, "X2", x2)
            result:SetInformation(source, "p", p)
            result:SetEffectSize(source, "Cramer's V", v)
            result:SetVariable1(variable)
            result:SetSampleSize(design:GetNumberOfSubjects())
            result:SetExperimentalDesign(design)
            result:SetFormalTestName("Pearson's Chi-Squared Goodness of Fit Test")
            results:Add(result)
            i = i + 1
        end
    end

    /*
        This action represents a goodness of fit chi-squared test on one or more columns of data.
        For each column, it calculates the observed values by counting the frequencies of unique items.
        Then it compares the observed with the user-supplied expected percentages.
        The percentages must add up to 1.0, and there must be a percent for each category.

        H0: The population fits the given distribution.
        Ha: The population does not fit the given distribution.

        Attribute: Returns the CompareCountsResult between a column and a given expected percent. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
        frame:AddSelectedColumns("smoker")

        NumberColumn percent
        percent:Add(0.4)
        percent:Add(0.6)

        CompareCounts compare
        compare:GoodnessOfFitAgainstExpectedPercents(frame, percent)
        compare:GetSummary()
    */
    action GoodnessOfFitAgainstExpectedPercents(DataFrame frame, DataFrameColumn percents)
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected manually
            me:Calculate(frame)
        end
        if not percents:IsNumberColumn()
            alert("Expected percents must be a number column. Example: 0.5")
        else
            Summarize checkPercents
            checkPercents:Calculate(percents)
            if checkPercents:GetSum() not= 1.0
                alert("Expected percents must add up to 1.0")
            end
        end
        goodnessOfFit = true
        integer i = 0
        repeat while i < design:GetGroupsFrame():GetSize()
            DataFrame observed = CalculateObserved(design:GetGroupsFrame():GetColumn(i))
            DataFrame percentFrame
            percentFrame:AddColumn(observed:GetColumn(0):Copy())
            percentFrame:AddColumn(percents)
            DataFrame expected = CalculateExpectedFromPercentOfTotal(observed, percentFrame)
            integer rows = observed:GetColumn(0):GetSize()
            integer cols = observed:GetColumns():GetSize()
            number x2 = ChiSquare(observed:GetColumn(1), expected:GetColumn(1))  
            number df = (rows-1)*(cols-1)
            distribution:Setup(df)
            number p = 1.0 - distribution:CumulativeDistribution(x2)
            number v = math:SquareRoot(x2 / (design:GetNumberOfSubjects() * df))

            text variable = design:GetGroupsFrame():GetColumn(i):GetHeader()

            Array<text> sources
            text source = variable
            sources:Add(source)
            CompareCountsResult result
            result:SetGroupsFrame(design:GetGroupsFrame())
            result:SetGoodnessOfFit(true)
            result:SetSources(sources)
            result:SetObserved(observed)
            result:SetExpected(expected)
            result:SetResiduals(CalculateResiduals(observed, expected))
            result:SetAdjustedResiduals(CalculateAdjustedResiduals(observed, expected))
            result:SetTestStatistic(source, "X2", x2)
            result:SetDegreesOfFreedom(source, "X2", df)
            result:SetProbabilityValue(source, "X2", p)
            result:SetInformation(source, "X2", x2)
            result:SetInformation(source, "p", p)
            result:SetEffectSize(source, "Cramer's V", v)
            result:SetVariable1(variable)
            result:SetSampleSize(design:GetNumberOfSubjects())
            result:SetExperimentalDesign(design)
            result:SetFormalTestName("Pearson's Chi-Squared Goodness of Fit Test")
            results:Add(result)
            i = i + 1
        end
    end

    /*
        This action represents a goodness of fit chi-squared test on one or more columns of data.
        For each column, it calculates the observed values by counting the frequencies of unique items.
        Then it compares the observed with the user-supplied expected percentages.
        The percentages must add up to 1.0, and there must be a percent for each category.

        H0: The population fits the given distribution.
        Ha: The population does not fit the given distribution.

        Attribute: Returns the CompareCountsResult between a column and a given expected percent. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
        frame:AddSelectedColumns("smoker")

        TextColumn category
        category:Add("yes")
        category:Add("no")

        NumberColumn percent
        percent:Add(0.4)
        percent:Add(0.6)

        DataFrame expected
        expected:AddColumn(category)
        expected:AddColumn(percent)

        CompareCounts compare
        compare:GoodnessOfFitAgainstExpectedPercents(frame, expected)
        compare:GetSummary()
    */
    action GoodnessOfFitAgainstExpectedPercents(DataFrame frame, DataFrame percents)
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected manually
            me:Calculate(frame)
        end
        if percents:GetColumns():GetSize() not= 2
            alert("Expected percents DataFrame must include a text column (for the category) and a number column (for the percent). Example: male, 0.5")
        else
            Summarize checkPercents
            checkPercents:Calculate(percents:GetColumn(1))
            if checkPercents:GetSum() not= 1.0
                alert("Expected percents must add up to 1.0")
            end
        end
        goodnessOfFit = true
        integer i = 0
        repeat while i < design:GetGroupsFrame():GetSize()
            DataFrame observed = CalculateObservedToFollowGivenOrder(design:GetGroupsFrame():GetColumn(i), percents:GetColumn(0))
            DataFrame expected = CalculateExpectedFromPercentOfTotal(observed, percents)
            if observed:GetColumns():GetSize() > 0
                integer rows = observed:GetColumn(0):GetSize()
                integer cols = observed:GetColumns():GetSize()
                number x2 = ChiSquare(observed:GetColumn(1), expected:GetColumn(1))  
                number df = (rows-1)*(cols-1)
                distribution:Setup(df)
                number p = 1.0 - distribution:CumulativeDistribution(x2)
                number v = math:SquareRoot(x2 / (design:GetNumberOfSubjects() * df))
        
                text variable = design:GetGroupsFrame():GetColumn(i):GetHeader()
    
                Array<text> sources
                text source = variable
                sources:Add(source)
                CompareCountsResult result
                result:SetGroupsFrame(design:GetGroupsFrame())
                result:SetGoodnessOfFit(true)
                result:SetSources(sources)
                result:SetObserved(observed)
                result:SetExpected(expected)
                result:SetResiduals(CalculateResiduals(observed, expected))
                result:SetAdjustedResiduals(CalculateAdjustedResiduals(observed, expected))
                result:SetTestStatistic(source, "X2", x2)
                result:SetDegreesOfFreedom(source, "X2", df)
                result:SetProbabilityValue(source, "X2", p)
                result:SetInformation(source, "X2", x2)
                result:SetInformation(source, "p", p)
                result:SetEffectSize(source, "Cramer's V", v)
                result:SetVariable1(variable)
                result:SetSampleSize(design:GetNumberOfSubjects())
                result:SetExperimentalDesign(design)
                result:SetFormalTestName("Pearson's Chi-Squared Goodness of Fit Test")
                results:Add(result)
            end
            i = i + 1
        end
    end

    /*
        This action represents a goodness of fit chi-squared test on a single column of data.
        It calculates the observed values by counting the frequencies of unique items.
        Then it compares the observed with the user-supplied expected counts.

        H0: The population fits the given distribution.
        Ha: The population does not fit the given distribution.

        Attribute: Returns the CompareCountsResult between a column and a given expected count. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
        frame:AddSelectedColumns("smoker")

        TextColumn category
        category:Add("yes")
        category:Add("no")

        NumberColumn count
        count:Add(60)
        count:Add(50)

        DataFrame expected
        expected:AddColumn(category)
        expected:AddColumn(count)

        CompareCounts compare
        compare:GoodnessOfFitAgainstExpectedCounts(frame, expected)
        compare:GetSummary()
    */
    action GoodnessOfFitAgainstExpectedCounts(DataFrame frame, DataFrame expected)
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected manually
            me:Calculate(frame)
        end
        if expected:GetColumns():GetSize() not= 2
            alert("Expected Counts DataFrame must include a text column (for the category) and a number column (for the count). Example: male, 400")
        end
        goodnessOfFit = true
        integer i = 0
        repeat while i < design:GetGroupsFrame():GetSize()
            DataFrame observed = CalculateObservedToFollowGivenOrder(design:GetGroupsFrame():GetColumn(i), expected:GetColumn(0))
            integer rows = observed:GetColumn(0):GetSize()
            integer cols = observed:GetColumns():GetSize()
            number x2 = ChiSquare(observed:GetColumn(1), expected:GetColumn(1))  
            number df = (rows-1)*(cols-1)
            distribution:Setup(df)
            number p = 1.0 - distribution:CumulativeDistribution(x2)
            number v = math:SquareRoot(x2 / (design:GetNumberOfSubjects() * df))
    
            text variable = design:GetGroupsFrame():GetColumn(i):GetHeader()

            Array<text> sources
            text source = variable
            sources:Add(source)
            CompareCountsResult result
            result:SetGroupsFrame(design:GetGroupsFrame())
            result:SetGoodnessOfFit(true)
            result:SetSources(sources)
            result:SetObserved(observed)
            result:SetExpected(expected)
            result:SetResiduals(CalculateResiduals(observed, expected))
            result:SetAdjustedResiduals(CalculateAdjustedResiduals(observed, expected))
            result:SetTestStatistic(source, "X2", x2)
            result:SetDegreesOfFreedom(source, "X2", df)
            result:SetProbabilityValue(source, "X2", p)
            result:SetInformation(source, "X2", x2)
            result:SetInformation(source, "p", p)
            result:SetEffectSize(source, "Cramer's V", v)
            result:SetVariable1(variable)
            result:SetSampleSize(design:GetNumberOfSubjects())
            result:SetExperimentalDesign(design)
            result:SetFormalTestName("Pearson's Chi-Squared Goodness of Fit Test")
            results:Add(result)
            i = i + 1
        end
    end

    /*
        This action calculates the observed counts by simply counting the 
        frequency of each unique item in the column.

        Attribute: Returns the Observed Counts DataFrame.
    */
    private action CalculateObserved(DataFrameColumn column) returns DataFrame
        // Count unique items
        DataFrameColumn rowHeaders = column:Copy(true, true)
        HashTable<text,integer> hash = column:CalculateValueCountAsText() 
        integer rows = rowHeaders:GetSize()

        NumberColumn observedCount
        observedCount:SetHeader("count")
        integer i = 0
        repeat while i < rowHeaders:GetSize()
            if hash:HasKey(rowHeaders:GetAsText(i))
                observedCount:Add(hash:GetValue(rowHeaders:GetAsText(i)))
            end
            i = i + 1
        end

        DataFrame observed
        observed:AddColumn(rowHeaders)
        observed:AddColumn(observedCount)
        return observed  
    end

    /*
        This action calculates the observed counts the same way CalculateObserved() does.
        The difference here is the returned DataFrame Observed rowHeaders will be in the same 
        order that the user gave as an expected count or percent.
        This is necessary to ensure the correct observed values will be compared to the correct 
        expected values.

        Attribute: Returns the Observed Counts DataFrame.
    */
    private action CalculateObservedToFollowGivenOrder(DataFrameColumn column, DataFrameColumn expectedRowHeaders) returns DataFrame
        // Count unique items
        DataFrame observed
        DataFrameColumn rowHeaders = expectedRowHeaders:Copy()
        rowHeaders:SetHeader(column:GetHeader())
        HashTable<text,integer> hash = column:CalculateValueCountAsText() 
        integer rows = rowHeaders:GetSize()

        NumberColumn observedCount
        observedCount:SetHeader("count")
        integer i = 0
        repeat while i < rowHeaders:GetSize()
            if hash:HasKey(rowHeaders:GetAsText(i))
                observedCount:Add(hash:GetValue(rowHeaders:GetAsText(i)))
            else
                observedCount:Add(0)
            end
            i = i + 1
        end

        observed:AddColumn(rowHeaders)
        observed:AddColumn(observedCount)
        return observed  
    end

    /*
        This action calculates the observed counts across two variables.
        It does so by implementing the CrossTab calculation.

        Attribute: Returns the Observed Counts DataFrame.
    */
    private action CalculateObserved(DataFrameColumn column1, DataFrameColumn column2) returns DataFrame
        DataFrame observed
        observed:AddColumn(column1)
        observed:AddColumn(column2)

        observed:AddSelectedColumn(0)
        observed:AddSelectedColumn(1)

        return observed:CrossTab()
    end

    /*
        This action calculates the expected counts using the column and 
        row sums of the observed counts DataFrame.

        Attribute: Returns the Expected Counts DataFrame.
    */
    private action CalculateExpectedFromObserved(DataFrame observed) returns DataFrame
        DataFrame expected
        if observed:GetColumns():GetSize() > 0 and observed:GetColumn(0):GetSize() > 0
            expected:AddColumn(observed:GetColumn(0):Copy()) // First column is just row headers.

            DataFrame observedCopy = observed:Copy()
            observedCopy:RemoveColumnAt(0) //remove row headers for now
            Matrix matrix = observedCopy:ConvertToMatrix()

            number totalSum = matrix:GetTotal()
            Array <number> colSums
            integer i = 0
            repeat while i < matrix:GetColumns()
                colSums:Add(matrix:GetColumn(i):GetTotal())
                i = i + 1
            end

            Array <number> rowSums
            i = 0
            repeat while i < matrix:GetRows()
                rowSums:Add(matrix:GetRow(i):GetTotal())
                i = i + 1
            end

            i = 0
            repeat while i < colSums:GetSize()
                NumberColumn expect
                expect:SetHeader(observed:GetColumn(i+1):GetHeader())
                j = 0
                repeat while j < rowSums:GetSize()
                    number expectedValue = colSums:Get(i)*rowSums:Get(j)/totalSum
                    if goodnessOfFit
                        expectedValue = totalSum/rowSums:GetSize()
                    end
                    expect:Add(expectedValue)
                    j = j + 1
                end
                expected:AddColumn(expect)
                i = i + 1
            end
        end
        return expected
    end

    /*
        This action calculates the expected counts using the user-provided 
        percentages of the total.

        Attribute: Returns the Expected Counts DataFrame.
    */
    private action CalculateExpectedFromPercentOfTotal(DataFrame observed, DataFrame percents) returns DataFrame
        DataFrame expected
        if observed:GetColumns():GetSize() > 0 and observed:GetColumn(0):GetSize() > 0
            expected:AddColumn(observed:GetColumn(0):Copy()) // First column is just row headers.
            integer cols = observed:GetColumns():GetSize()
            integer rows = observed:GetColumn(0):GetSize()

            DataFrame observedCopy = observed:Copy()
            observedCopy:RemoveColumnAt(0) //remove row headers for now
            Matrix matrix = observedCopy:ConvertToMatrix()

            number totalSum = matrix:GetTotal()

            i = 1
            repeat while i < cols
                NumberColumn expect
                expect:SetHeader(observed:GetColumn(i):GetHeader())
                j = 0
                repeat while j < rows
                    number expectedValue = 0
                    if j < percents:GetColumn(i):GetSize()
                        expectedValue = totalSum*percents:GetColumn(i):GetAsNumber(j)
                    else
                        alert("You only gave "+ percents:GetColumn(i):GetSize() + " percent values but there are "+ (j+1) +" observed categories.")
                    end
                    expect:Add(expectedValue)
                    j = j + 1
                end
                // Checking for left over % values... meaning the user gave too many
                if j < percents:GetColumn(i):GetSize()
                    alert("You gave "+ percents:GetColumn(i):GetSize() + " percent values but there are only "+ j +" observed categories.")
                end
                expected:AddColumn(expect)
                i = i + 1
            end
        end
        return expected
    end

    // Pearson residuals (observed - expected) / sqrt(expected)
    // For more information: https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1269&context=pare
    private action CalculateResiduals(DataFrame observed, DataFrame expected) returns DataFrame
        observed:SelectAllColumns()
        observed:RemoveSelectedColumn(0) // First column is just row headers.
        expected:SelectAllColumns()
        expected:RemoveSelectedColumn(0) // First column is just row headers.
        DataFrame observedCopy = observed:CopySelectedColumns()
        Matrix observedMatrix = observedCopy:ConvertToMatrix()
        Matrix expectedMatrix = expected:CopySelectedColumns():ConvertToMatrix()

        Matrix rowSums = observedMatrix:SumByRow()
        Matrix colSums = observedMatrix:SumByColumn()
        number total = rowSums:GetTotal()
        
        Matrix residualsMatrix = observedMatrix:SubtractElements(expectedMatrix)
        integer i = 0
        repeat while i < rowSums:GetRows()
            integer j = 0 
            repeat while j < colSums:GetColumns()
                number eValue = expectedMatrix:Get(i,j)
                if eValue = 0
                    alert("The expected values cannot be 0")
                end
                number rValue = residualsMatrix:Get(i, j) / math:SquareRoot(eValue)
                residualsMatrix:Set(i, j, rValue)
                j = j + 1 
            end
            i = i + 1 
        end

        Array<text> columnHeaders = observedCopy:GetHeaders()
        DataFrame residuals = residualsMatrix:ConvertToDataFrame(columnHeaders)
        residuals:AddColumn(0, observed:GetColumn(0):Copy()) // Add row headers as first column.        

        return residuals
    end

    // Adjusted standardized residuals (observed - expected) / sqrt(expected * (1 - rowSum/total) * (1 - colSum/total))
    // For more information: https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1269&context=pare
    private action CalculateAdjustedResiduals(DataFrame observed, DataFrame expected) returns DataFrame
        observed:SelectAllColumns()
        observed:RemoveSelectedColumn(0) // First column is just row headers.
        expected:SelectAllColumns()
        expected:RemoveSelectedColumn(0) // First column is just row headers.
        DataFrame observedCopy = observed:CopySelectedColumns()
        Matrix observedMatrix = observedCopy:ConvertToMatrix()
        Matrix expectedMatrix = expected:CopySelectedColumns():ConvertToMatrix()

        Matrix rowSums = observedMatrix:SumByRow()
        Matrix colSums = observedMatrix:SumByColumn()
        number total = rowSums:GetTotal()
        
        Matrix residualsMatrix = observedMatrix:SubtractElements(expectedMatrix)
        integer i = 0
        repeat while i < rowSums:GetRows()
            integer j = 0 
            repeat while j < colSums:GetColumns()
                number eValue = expectedMatrix:Get(i,j)
                if eValue = 0
                    alert("The expected values cannot be 0")
                end
                number rValue = residualsMatrix:Get(i, j) / math:SquareRoot(eValue * (1.0 - rowSums:Get(i,0) / total) * (1.0 - colSums:Get(0,j) / total))
                residualsMatrix:Set(i, j, rValue)
                j = j + 1 
            end
            i = i + 1 
        end

        Array<text> columnHeaders = observedCopy:GetHeaders()
        DataFrame residuals = residualsMatrix:ConvertToDataFrame(columnHeaders)
        residuals:AddColumn(0, observed:GetColumn(0):Copy()) // Add row headers as first column.        

        return residuals
    end

    /*
        This action compares two number columns (observed and expected)
        and calculates the X-squared critical value / test statistic.

        Attribute: Returns the chi-squared test statistic.
    */

    private action ChiSquare(DataFrameColumn observed, DataFrameColumn expected) returns number
        if observed = undefined
            alert("Observed column is undefined.")
        end
        if expected = undefined
            alert("Expected column is undefined.")
        end

        if observed:GetSize() not= expected:GetSize()
            alert("Observed and Expected must be the same size.")
        end

        // Verify Observed. All values must be 0 or greater
        if not observed:IsNumberColumn() and not observed:IsIntegerColumn()
            alert("Observed must a numerical column.")
        end
        Summarize observedSummary
        observedSummary:Calculate(observed)
        if observedSummary:GetMinimum() < 0
            alert("Observed cannot have negative values.")
        end
        number observedSum = observedSummary:GetSum()

        // Verify Expected. All values must be greater than 0. Cannot be 0?
        if not expected:IsNumberColumn() and not expected:IsIntegerColumn()
            alert("Expected must a numerical column.")
        end
        Summarize expectedSummary
        expectedSummary:Calculate(expected)
        if expectedSummary:GetMinimum() <= 0
            alert("Expected must have positive values.")
        end
        if expectedSummary:GetMinimum() < 5
            approximationWarning = true
        end
        number expectedSum = expectedSummary:GetSum()

        if observedSum = 0 or expectedSum = 0
            alert("Counts cannot be all zeros")
        end

        //If sums are different, set a weight
        boolean unequalCounts = false
        number weight = 0.0
        if observedSum not= expectedSum
            unequalCounts = true
            weight = math:SquareRoot(observedSum / expectedSum)
        end

        number ratio = 1.0        
        boolean rescale = false      
        if (math:AbsoluteValue(expectedSum - observedSum) > 10.0e-6)
            ratio = observedSum / expectedSum
            rescale = true
        end
        number sumSquared = 0
        integer i = 0
        repeat while i < observed:GetSize()
            if rescale
                number dev = observed:GetAsNumber(i) - ratio * expected:GetAsNumber(i)
                if unequalCounts
                    dev = (observed:GetAsNumber(i)/weight) - ratio * (expected:GetAsNumber(i)*weight)
                end
                sumSquared = sumSquared + (dev * dev / (ratio * expected:GetAsNumber(i)))
            else
                number dev = observed:GetAsNumber(i) - expected:GetAsNumber(i)
                if unequalCounts
                    dev = (observed:GetAsNumber(i)/weight) - (expected:GetAsNumber(i)*weight)
                end
                sumSquared = sumSquared + (dev * dev / expected:GetAsNumber(i))
            end
            i = i + 1
        end
    
        return sumSquared
    end

    /*
        This action uses a KxMxV contingency table of observed and expected counts 
        to calculate the chi-squared test statistic.
        K is the number of independent groups       (example: treatmentA, treatmentB, and control)
        M is the number of repeated measurements    
        V is the number of outcome categories       (example: high, low and medium)
        For this test: K >= 2, M = 1 and V >= 2

        Attribute: Returns the chi-squared test statistic.
    */
    private action ChiSquare(DataFrame observed, DataFrame expected) returns number 
        if observed = undefined
            alert("Observed dataframe is undefined.")
        end
        if expected = undefined
            alert("Expected dataframe is undefined.")
        end

        if observed:GetSize() not= expected:GetSize()
            alert("Observed and Expected must be the same size.")
        end

        boolean twoByTwoTable = observed:GetSize() = 3 and observed:GetColumn(0):GetSize() = 2 // The first column is row headers

        number x2 = 0
        integer i = 1 // The first column is row headers
        repeat while i < observed:GetColumns():GetSize() and i < expected:GetColumns():GetSize()
            DataFrameColumn observe = observed:GetColumn(i)
            DataFrameColumn expect = expected:GetColumn(i)
            // Verify Observed.
            if not observe:IsNumberColumn() and not observe:IsIntegerColumn()
                alert("Observed must a numerical column.")
            end
    
            // Verify Expected.
            if not expect:IsNumberColumn() and not expect:IsIntegerColumn()
                alert("Expected must a numerical column.")
            end

            integer j = 0
            repeat while j < observe:GetSize() and j < expect:GetSize()
                if expect:GetAsNumber(j) < 5 and not approximationWarning
                    approximationWarning = true
                end

                if useContinuityCorrection and twoByTwoTable // Yate's correction
                    number top = math:AbsoluteValue(observe:GetAsNumber(j) - expect:GetAsNumber(j)) - 0.5
                    x2 = x2 + (top * top / expect:GetAsNumber(j))
                else
                    number top = observe:GetAsNumber(j) - expect:GetAsNumber(j)
                    x2 = x2 + (top * top / expect:GetAsNumber(j))
                end
                j = j + 1
            end
            i = i + 1
        end
        return x2
    end

    /*
        This action uses a KxMxV contingency table of observed counts of paired data 
        to calculate the chi-squared test statistic.
        K is the number of independent groups       
        M is the number of repeated measurements    (example: before and after)
        V is the number of outcome categories       (example: yes and no)
        For this test: K = 1, M = 2 and V = 2

        Attribute: Returns the chi-squared test statistic.
    */
    private action McNemar(DataFrame observed, text source, CompareCountsResult result) returns number 
        number x2 = 0
        number cohensG = 0
        if observed:GetSize() = 3 and observed:GetColumn(0):GetSize() = 2 // The first column is row headers
            number b = observed:GetColumn(2):GetAsNumber(0)
            number c = observed:GetColumn(1):GetAsNumber(1)
            cohensG = math:AbsoluteValue(math:MaximumOf(b,c) / (b + c))

            if useContinuityCorrection // Edwards correction
                number top = math:AbsoluteValue(b - c) - 1.0
                x2 = top * top / (b + c)
            else
                number top = b - c
                x2 = top * top / (b + c)
            end
        end
        cohensG = cohensG - 0.5
        result:SetEffectSize(source, "Cohen's g", cohensG)
        return x2
    end   

    /*
        This action uses a KxMxV contingency table of observed counts of paired data 
        to calculate the chi-squared test statistic.
        K is the number of independent groups 
        M is the number of repeated measurements    (example: before and after)
        V is the number of outcome categories       (example: for, against and neutral)
        For this test: K = 1, M = 2 and V >= 3

        Attribute: Returns the chi-squared test statistic.
    */
    private action McNemarBowker(DataFrame observed, text source, CompareCountsResult result) returns number         
        // https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Multiple_Correlated_Proportions-McNemar-Bowker_Test_of_Symmetry.pdf
        // Since our tables are input categories x outcome categories we can just grab the first column.
        number k = observed:GetColumns():GetSize()-1 // number of output categories
        number x2 = 0
        number cohensG = 0
        integer col = 2 // The first column is row headers
        repeat while col < observed:GetColumns():GetSize()
            integer row = 0
            repeat while row < col-1
                number b = observed:GetColumn(col):GetAsNumber(row)
                number c = observed:GetColumn(row+1):GetAsNumber(col-1)
                number top = b - c
                cohensG = cohensG + (math:AbsoluteValue(math:MaximumOf(b,c) / (b + c)) - 0.5)

                x2 = x2 + top * top / (b + c)
                row = row + 1
            end
            col = col + 1
        end
        cohensG = cohensG / k
        result:SetEffectSize(source, "Cohen's g", cohensG)
        return x2
    end   

    /*
        This action uses a KxMxV contingency table of observed counts of repeated data 
        to calculate the chi-squared test statistic.
        K is the number of independent groups 
        M is the number of repeated measurements (example: before, during and after)
        V being the number of outcome categories (example: correct and incorrect)
        For this test: K = 1, M >= 3 and V = 2

        Attribute: Returns the chi-squared test statistic.
    */
    private action Cochran(DataFrame observed, text source, CompareCountsResult result) returns number 
        integer k = design:GetNumberOfMeasurements()
        integer n = design:GetNumberOfSubjects()

        DataFrameColumn levels = design:GetDesignFrame():GetColumn(design:GetDependentVariables():Get(0)):Copy(true,true)
        Matrix dummyCodedData = EncodeOutputCategoriesIntoMatrix(levels)
        Matrix subjectCounts = dummyCodedData:SumByRow()
        Matrix measureCounts = dummyCodedData:SumByColumn()      

        // For more information: https://stats.stackexchange.com/questions/9867/effect-size-of-cochrans-q
        // https://peterstatistics.com/CrashCourse/5-ThreeVarPair/binary/MultipleBinaryPaired3c.html#:~:text=For%20the%20omnibus%20test%20(the,%2C%20%26%20Mielke%2C%202007).
        Matrix measureOnes = measureCounts                          // how many 1s per column
        Matrix measureZeros = measureCounts:Multiply(-1.0):Add(n)     // how many 0s per column
        number measureDifferenceSum = measureOnes:MultiplyElements(measureZeros):GetTotal() // sum of all differences
        number nChoose2 = math:Factorial(n) / math:Factorial(2) * math:Factorial(n - 2)
        number measureDelta = (1.0 / k * nChoose2) * measureDifferenceSum
        Matrix subjectOnesProp = subjectCounts:Divide(cast(number, k))                                          // proportion of 1s per row
        Matrix subjectDifference = subjectOnesProp:MultiplyElements(subjectOnesProp:Multiply(-1.0):Add(1.0))    // sum of all proportion differences
        number subjectOnesPropSum = subjectOnesProp:GetTotal()
        number subjectDifferenceSum = subjectDifference:GetTotal()
        number subjectDelta = (2.0 / (n * (n - 1.0))) * (subjectOnesPropSum * (n - subjectOnesPropSum) - subjectDifferenceSum)
        number R = 1.0 - measureDelta / subjectDelta
        result:SetEffectSize(source, "chance-corrected R", R) // Chance corrected R https://alexisdinno.com/stata/cochranq.txt

        // https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Cochrans_Q_Test.pdf
        number sumOfMeasureSquaredSums = measureCounts:GetSumOfSquares()        
        number sumOfSubjectSums = measureCounts:GetTotal()                      
        number sumOfSubjectSquaredSums = subjectCounts:GetSumOfSquares()  
        number q = (k - 1) * (k * sumOfMeasureSquaredSums - (sumOfSubjectSums * sumOfSubjectSums)) / (k * sumOfSubjectSums - sumOfSubjectSquaredSums)
        return q
    end  

    private action EncodeOutputCategoriesIntoMatrix(DataFrameColumn levels) returns Matrix
        Matrix encoded
        encoded:Fill(design:GetGroupsFrame():GetColumn(0):GetSize(), design:GetGroupsFrame():GetSize(), 0)
        HashTable<text, integer> encoding
        integer i = 0
        repeat while i < levels:GetSize()
            encoding:Add(levels:GetAsText(i), i)
            i = i + 1
        end
        i = 0 // first column is row headers, second column we will leave as encoded with 0
        repeat while i < design:GetGroupsFrame():GetSize()
            DataFrameColumn group = design:GetGroupsFrame():GetColumn(i)
            j = 0
            repeat while j < group:GetSize()
                encoded:Set(j,i,encoding:GetValue(group:GetAsText(j)))
                j = j + 1
            end
            i = i + 1
        end        
        return encoded
    end

    /*
        This returns the probability if only one result exists.

        Attribute: Returns the P-Value. 
    */
    action GetProbabilityValue returns number
        return GetResult():GetProbabilityValue()
    end

    /*
        This returns the degrees of freedom if only one result exists.

        Attribute: Returns the Degrees of Freedom. 
    */
    action GetDegreesOfFreedom returns number
        return GetResult():GetDegreesOfFreedom()
    end

    /*
        This returns the x2 test statistic if only one result exists.

        Attribute: Returns the x2 test statistic. 
    */
    action GetTestStatistic returns number
        return GetResult():GetTestStatistic()
    end


    /*
        This returns the observed frame if only one result exists.

        Attribute: Returns the observed frame. 
    */
    action GetObserved returns DataFrame
        return GetResult():GetObserved()
    end

    /*
        This returns the expected frame if only one result exists.

        Attribute: Returns the expected frame. 
    */
    action GetExpected returns DataFrame
        return GetResult():GetExpected()
    end

    /*
        This returns the residuals frame if only one result exists.

        Attribute: Returns the residuals frame. 
    */
    action GetResiduals returns DataFrame
        return GetResult():GetResiduals()
    end


    /*
        This returns a result if only one exists. If there are more than one, 
        this action returns undefined.

        Attribute: Returns the CompareCountsResult. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
        frame:AddSelectedColumns("region")
        CompareCounts compare = frame:CompareSelectedCounts()
        
        CompareCountsResult result = compare:GetResult()
    */
    action GetResult returns CompareCountsResult
        if GetResults():GetSize() = 0
            alert("There are no results calculated")
        elseif GetResults():GetSize() = 1
            return GetResults():Get(0)
        else
            alert("There is more than one test result, use GetResults() for an array of all results")
        end
    end

    /*
        This returns the results between all computed columns.

        Attribute: Returns the CompareCountsResults. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareCounts compare
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:AddColumn(2)
        frame:Calculate(compare)
        
        Array<CompareCountsResult> results = compare:GetResults()
    */
    action GetResults returns Array<CompareCountsResult>
        return results
    end

    /*
        This returns the pairwise results if only one result exists.
        Pairwise results are only calculated in N-sample tests, 
        otherwise this will return undefined.

        Attribute: Returns the pairwise results. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
        use Libraries.Compute.Statistics.Reporting.CompareCountsResult
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareCounts compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestPairwise()
        frame:Calculate(compare)

        Array<CompareMeansResult> pairwise = compare:GetPairwiseResults() 
    */
    action GetPairwiseResults returns Array<CompareCountsResult>
        return GetResult():GetPairwiseResults()
    end

    /*
        This returns the pairwise summary if only one result exists.
        Pairwise results are only calculated in N-sample tests, 
        otherwise this will return nothing.

        Attribute: Returns the pairwise summary.
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareCounts
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareCounts compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestPairwise()
        frame:Calculate(compare)

        output compare:GetPairwiseSummary() 
    */
    action GetPairwiseSummary returns text
        return GetResult():GetPairwiseSummary()
    end

    /*
        This action summarizes the results and lists them informally.
    */
    action GetSummary returns text
        text summary = ""
        text lf = summary:GetLineFeed()
        CompareCountsResult result 
        i = 0
        repeat while i < GetResults():GetSize()
            result = GetResults():Get(i)

            summary = summary + lf
            summary = summary + result:GetSummary()
            summary = summary + lf
            i = i + 1
        end
        return summary
    end

    /*
        This action summarizes the results and places them into formal academic language, in 
        APA format.

        For more information: https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf
    */
    action GetFormalSummary returns text
        StatisticsFormatting format = GetStatisticalFormatting()
        text summary = ""
        text lf = summary:GetLineFeed()
        CompareCountsResult result 
        i = 0
        repeat while i < GetResults():GetSize()
            result = GetResults():Get(i)
            result:SetFormat(format)

            summary = summary + lf
            summary = summary + result:GetFormalSummary()
            summary = summary + lf
            i = i + 1
        end
        return summary
    end

     /*
        This creates an HTML page with the results as its contents.  
    */
    action GetReport(File file)
        GetResult():GetReportResult(file)
    end

    /* Used in N-sample tests */
    action TestPairwise
        testPairwiseComparisons = true
    end

    /* Used in N-sample tests */
    action TestPairwise(boolean test)
        testPairwiseComparisons = test
        if not test
            skipPairwiseComparisons = true
        end
    end

    /* Used in 2-sample tests */
    action Paired(boolean paired)
        me:repeated = paired
    end

    /* Used in 2-sample tests */
    action Paired returns boolean
        return repeated
    end

    /* Used in N-sample tests */
    action RepeatedMeasures(boolean repeatedMeasures)
        me:repeated = repeatedMeasures
    end

    /* Used in N-sample tests */
    action RepeatedMeasures returns boolean
        return repeated
    end

    action SetExperimentalDesign(ExperimentalDesign design)
        me:design = design:Copy()
    end

    // This is the class that holds all design selections and design frame.
    action GetExperimentalDesign returns ExperimentalDesign
        return design
    end

    /* Strict method is the default for most tests if another is not selected */
    action CorrectFamilyWiseError(boolean correctFamilyWiseError)
        me:correctFamilyWiseError = correctFamilyWiseError
        if not useLenientCorrection
            useStrictCorrection = correctFamilyWiseError
        end
    end

    /* Choose strict pairwise comparison as correction for N-sample pairwise tests */
    action UseStrictCorrection(boolean useStrictCorrection)
        correctFamilyWiseError = useStrictCorrection
        me:useStrictCorrection = useStrictCorrection
        if useStrictCorrection
            useLenientCorrection = false
        end
    end

    /* Choose lenient multiple comparison as correction for N-sample pairwise tests */
    action UseLenientCorrection(boolean useLenientCorrection)
        correctFamilyWiseError = useLenientCorrection
        me:useLenientCorrection = useLenientCorrection
        if useLenientCorrection
            useStrictCorrection = false
        end
    end

    /* Returns true for correction */
    action CorrectFamilyWiseError returns boolean
        return correctFamilyWiseError
    end

    /* Returns true for strict pairwise comparison as correction for N-sample pairwise tests */
    action UsingStrictCorrection returns boolean
        return useStrictCorrection
    end

    /* Returns true for lenient multiple comparison as correction for N-sample pairwise tests */
    action UsingLenientCorrection returns boolean
        return useLenientCorrection
    end

    /* Returns true for multiple comparisons to use the model as a reference for N-sample pairwise tests */
    action UsingFittedApproach returns boolean
        return useFittedApproach
    end

    /* Choose fitted (unplanned) approach pairwise comparisons for N-sample pairwise tests */
    action UseFittedApproach(boolean useFittedApproach)
        me:useFittedApproach = useFittedApproach
        me:useUnfittedApproach = not useFittedApproach
    end

    /* Returns true for multiple comparisons to use individual tests for N-sample pairwise tests */
    action UsingUnfittedApproach returns boolean
        return useUnfittedApproach
    end

    /* Choose unfitted (planned) approach pairwise comparisons for N-sample pairwise tests */
    action UseUnfittedApproach(boolean useUnfittedApproach)
        me:useUnfittedApproach = useUnfittedApproach
        me:useFittedApproach = not useUnfittedApproach
    end

    /*
    INFORMATION:

    CompareCountsToDistribution is a Chi-squared Goodness Of Fit Test
    Check if sample data matches the population.
    For more information: https://en.wikipedia.org/wiki/Goodness_of_fit
    For more information: https://en.wikipedia.org/wiki/Chi-squared_test

    CompareSeveralRelatedCounts is a McNemar Test and a McNemar-Bowker Test Of Symmetry
    Difference between two paired groups when the outcome variable has two or more categories.
    For more information: https://en.wikipedia.org/wiki/McNemar%27s_test
    For more information: https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Multiple_Correlated_Proportions-McNemar-Bowker_Test_of_Symmetry.pdf

    CompareSeveralRelatedCounts is a Cochran Q Test
    Difference between three or more repeated groups when the outcome variable has two categories.
    For more information: https://en.wikipedia.org/wiki/Cochran%27s_Q_test

    CompareSeveralCounts is a Pearson Chi-squared Test Of Independence aka Test Of Association
    Difference between two or more independent groups when the outcome variable has two or more categories. 
    This test assumes most expected counts are at least 5 and none are less than 1.
    For more information: https://en.wikipedia.org/wiki/Chi-squared_test

    ** NOT IMPLEMENTED YET **
    ____________________ is a Binomial Test
    Test two possible outcomes' observed versus expected results.
    For more information: https://www.stats4stem.org/chi-square-test-for-homogeneity

    ** NOT IMPLEMENTED YET **
    ____________________ is a Chi-squared Test Of Homogeniety
    For more information: https://www.stats4stem.org/chi-square-test-for-homogeneity

    ** NOT IMPLEMENTED YET **
    ____________________ is a G-Test Of Goodness Of Fit Test
    For more information: https://en.wikipedia.org/wiki/G-test

    ** NOT IMPLEMENTED YET **
    ____________________ is a G-Test Of Independence
    For more information: https://en.wikipedia.org/wiki/G-test  

    ** NOT IMPLEMENTED YET **
    ____________________ is a Fisher's Exact Test
    Difference between three or more independent groups when the outcome variable has two or more categories 
    when counts are small and number of levels of the input factor are equal to number of levels of the output factor (nxn).
    For more information: https://en.wikipedia.org/wiki/Fisher%27s_exact_test    

    ** NOT IMPLEMENTED YET **
    ____________________ is a (Multi-Way) Cochran–Mantel–Haenszel Test Of Conditional Independence
    Difference between two independent groups when the outcome variable has two categories stratified by 
    one or more additional independent factors with two or more levels in each.
    This test assumes odds ratios are equal this can be tested using Breslow-Day or Woolf test.
    https://en.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics

    This class was partially adapted from the same model in Apache Commons, but was expanded 
    upon to simplify the library's use and add a variety of actions and tests that were missing.
    More information about this class can be found on its documentation page ChiSquaredTest:
    https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html
    */
end