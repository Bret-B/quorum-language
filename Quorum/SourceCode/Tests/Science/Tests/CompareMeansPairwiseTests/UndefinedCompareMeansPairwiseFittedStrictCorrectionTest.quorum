package Science.Tests

use Libraries.Testing.Test
use Libraries.Compute.Statistics.DataFrame
use Libraries.Compute.Statistics.Tests.CompareMeansPairwise
use Libraries.Compute.Statistics.Reporting.CompareMeansResult

/*
    This class tests a bonferroni procedure on pairwise comparisons with bonferroni correction
*/
class UndefinedCompareMeansPairwiseFittedStrictCorrectionTest is Test

    on create
        SetName("Calculate UndefinedCompareMeansPairwiseFittedStrictCorrectionTest")
    end

    action Run
        ColumnCalculationTest framer
        DataFrame frame 
        frame:LoadFromCommaSeparatedValue("y,x1,x2,x3
        2.0,4.0,-9.0,9
        6.0,7,-19.0,19
        3.0,4.0,-18.0,18
        9.0,8.0,-16.0,16
        15.0,17.0,-2.0,2
        1.0,,-4.0,4")
        frame:AddSelectedColumnRange(0,2)

        // Emmeans Standard
        CompareMeansPairwise compare
        compare:UseFittedApproach(true)
        compare:UseStrictCorrection(true)
        frame:Calculate(compare)
        // Compare y-x1
        CompareMeansResult result0 = compare:GetResults():Get(0)
        Check(result0:GetTestStatistic(), -0.5391887461014682)
        Check(result0:GetDegreesOfFreedom(), 14.0)
        Check(result0:GetProbabilityValue(), 1.0)
        // Compare y-x2
        CompareMeansResult result1 = compare:GetResults():Get(1)
        Check(result1:GetTestStatistic(), 4.9010513737899055)
        Check(result1:GetDegreesOfFreedom(), 14.0)
        Check(result1:GetProbabilityValue(), 7.015108460773164e-4)
        // Compare x1-x2
        CompareMeansResult result2 = compare:GetResults():Get(2)
        Check(result2:GetTestStatistic(), 5.212157878980858)
        Check(result2:GetDegreesOfFreedom(), 14.0)
        Check(result2:GetProbabilityValue(), 3.948838204758773e-4)

        // Emmeans Repeated Measures with gg correction!
        CompareMeansPairwise compare1
        compare1:Paired(true)
        compare1:UseFittedApproach(true)
        compare1:UseStrictCorrection(true)
        frame:Calculate(compare1)
        // Compare y-x1
        CompareMeansResult result01 = compare1:GetResults():Get(0)
        Check(result01:GetTestStatistic(), -0.35287261858121766)
        Check(result01:GetDegreesOfFreedom(), 4.143995146948485)
        Check(result01:GetProbabilityValue(), 1.0)
        // Compare y-x2
        CompareMeansResult result02 = compare1:GetResults():Get(1)
        Check(result02:GetTestStatistic(), 6.986877847908109)
        Check(result02:GetDegreesOfFreedom(), 4.143995146948485)
        Check(result02:GetProbabilityValue(), 0.005800838975367003)
        // Compare x1-x2
        CompareMeansResult result03 = compare1:GetResults():Get(2)
        Check(result03:GetTestStatistic(), 7.339750466489327)
        Check(result03:GetDegreesOfFreedom(), 4.143995146948485)
        Check(result03:GetProbabilityValue(), 0.004790566492504339)

        // Dunn Kruskal
        CompareMeansPairwise compare2
        compare2:Ranked(true)
        compare2:AssumeEqualVariances(false)
        compare2:UseFittedApproach(true)
        compare2:UseStrictCorrection(true)
        frame:Calculate(compare2)
        // Compare y-x1
        CompareMeansResult result3 = compare2:GetResults():Get(0)
        Check(result3:GetTestStatistic(), -0.599931829801519)
        Check(result3:GetProbabilityValue(), 1.0)
        // Compare y-x2
        CompareMeansResult result4 = compare2:GetResults():Get(1)
        Check(result4:GetTestStatistic(), 2.6312577567416473)
        Check(result4:GetProbabilityValue(), 0.02552084676002675)
        // Compare x1-x2
        CompareMeansResult result5 = compare2:GetResults():Get(2)
        Check(result5:GetTestStatistic(), 3.108737663516959)
        Check(result5:GetProbabilityValue(), 0.005636653941808456)

        // Dunn Friedman (not compared to other softwares).
        CompareMeansPairwise compare3
        compare3:Ranked(true)
        compare3:Paired(true)
        compare3:AssumeEqualVariances(false)
        compare3:UseFittedApproach(true)
        compare3:UseStrictCorrection(true)
        frame:Calculate(compare3)
        // Compare y-x1
        CompareMeansResult result6 = compare3:GetResults():Get(0)
        Check(result6:GetTestStatistic(), -0.9486832980505132)
        Check(result6:GetProbabilityValue(), 1.0)
        // Compare y-x2
        CompareMeansResult result7 = compare3:GetResults():Get(1)
        Check(result7:GetTestStatistic(), 1.8973665961010278)
        Check(result7:GetProbabilityValue(), 0.17333871337078932)
        // Compare x1-x2
        CompareMeansResult result8 = compare3:GetResults():Get(2)
        Check(result8:GetTestStatistic(), 2.846049894151541)
        Check(result8:GetProbabilityValue(), 0.013279577573759749)

        // Conover Kruskal
        CompareMeansPairwise compare4
        compare4:Ranked(true)
        compare4:AssumeEqualVariances(true)
        compare4:UseFittedApproach(true)
        compare4:UseStrictCorrection(true)
        frame:Calculate(compare4)
        // Compare y-x1
        CompareMeansResult result9 = compare4:GetResults():Get(0)
        Check(result9:GetTestStatistic(), -1.0436038093506035)
        Check(result9:GetDegreesOfFreedom(), 14.0)
        Check(result9:GetProbabilityValue(), 0.9430650733050578)
        // Compare y-x2
        CompareMeansResult result10 = compare4:GetResults():Get(1)
        Check(result10:GetTestStatistic(), 4.577171074965948)
        Check(result10:GetDegreesOfFreedom(), 14.0)
        Check(result10:GetProbabilityValue(), 0.0012923656516985334)
        // Compare x1-x2
        CompareMeansResult result11 = compare4:GetResults():Get(2)
        Check(result11:GetTestStatistic(), 5.407765193907667)
        Check(result11:GetDegreesOfFreedom(), 14.0)
        Check(result11:GetProbabilityValue(), 2.769347621761974e-4)

        // Conover Friedman - R's package PMCMR is incorrect as of 11/14/23
        CompareMeansPairwise compare5
        compare5:Ranked(true)
        compare5:Paired(true)
        compare5:AssumeEqualVariances(true)
        compare5:UseFittedApproach(true)
        compare5:UseStrictCorrection(true)
        frame:Calculate(compare5)
        // Compare y-x1
        CompareMeansResult result12 = compare5:GetResults():Get(0)
        Check(result12:GetTestStatistic(), -2.1213203435596433)
        Check(result12:GetDegreesOfFreedom(), 8.0)
        Check(result12:GetProbabilityValue(), 0.200063999999999)
        // Compare y-x2
        CompareMeansResult result13 = compare5:GetResults():Get(1)
        Check(result13:GetTestStatistic(), 4.2426406871192865)
        Check(result13:GetDegreesOfFreedom(), 8.0)
        Check(result13:GetProbabilityValue(), 0.008481895778503744)
        // Compare x1-x2
        CompareMeansResult result14 = compare5:GetResults():Get(2)
        Check(result14:GetTestStatistic(), 6.363961030678929)
        Check(result14:GetDegreesOfFreedom(), 8.0)
        Check(result14:GetProbabilityValue(), 6.520112089684815e-4)
    end
end